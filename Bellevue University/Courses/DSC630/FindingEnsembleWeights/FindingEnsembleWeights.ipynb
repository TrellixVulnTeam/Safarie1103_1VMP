{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import StratifiedShuffleSplit \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 61878 rows and 95 columns\n",
      "   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
      "0   1       1       0       0       0       0       0       0       0       0   \n",
      "1   2       0       0       0       0       0       0       0       1       0   \n",
      "2   3       0       0       0       0       0       0       0       1       0   \n",
      "3   4       1       0       0       1       6       1       5       0       0   \n",
      "4   5       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n",
      "0  ...        1        0        0        0        0        0        0   \n",
      "1  ...        0        0        0        0        0        0        0   \n",
      "2  ...        0        0        0        0        0        0        0   \n",
      "3  ...        0        1        2        0        0        0        0   \n",
      "4  ...        1        0        0        0        0        1        0   \n",
      "\n",
      "   feat_92  feat_93   target  \n",
      "0        0        0  Class_1  \n",
      "1        0        0  Class_1  \n",
      "2        0        0  Class_1  \n",
      "3        0        0  Class_1  \n",
      "4        0        0  Class_1  \n",
      "\n",
      "[5 rows x 95 columns]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "print(\"Training set has {0[0]} rows and {0[1]} columns\".format(train.shape))\n",
    "\n",
    "\n",
    "print(train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['target'].values\n",
    "X = train.drop(['target','id'], axis=1).values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61878 61878\n"
     ]
    }
   ],
   "source": [
    "print(len(X),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### we need a test set that we didn't train on to find the best weights for combining the classifiers\n",
    "sss = StratifiedShuffleSplit(n_splits=3, test_size=0.5, random_state=0)\n",
    "sss.get_n_splits(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=3, random_state=0, test_size=0.5,\n",
      "            train_size=None)\n",
      "TRAIN: [16365 12045 51942 ... 41566 18861 53743] TEST: [26592   605  6645 ... 49392 48873 28562]\n",
      "TRAIN: [18431 31941 15809 ...  6861  1398 29000] TEST: [  985 46992 33850 ... 43781 13446  1872]\n",
      "TRAIN: [ 8488 24999  4214 ... 19774 20536 38938] TEST: [40170 12652 28899 ... 20065 20650 44413]\n"
     ]
    }
   ],
   "source": [
    "print(sss)       \n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30939, 93), (30939, 93), (30939,), (30939,))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape,y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC LogLoss 0.4394301388153072\n"
     ]
    }
   ],
   "source": [
    "### building the classifiers\n",
    "clfs = []\n",
    "\n",
    "rfc1 = RandomForestClassifier(n_estimators=50, random_state=4141, n_jobs=-1)\n",
    "rfc1.fit(X_train, y_train)\n",
    "print('RFC LogLoss {score}'.format(score=log_loss(y_test, rfc.predict_proba(X_test))))\n",
    "clfs.append(rfc1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression LogLoss 0.6455660580111905\n",
      "RFC2 LogLoss 0.7210416613009594\n"
     ]
    }
   ],
   "source": [
    "### usually you'd use xgboost and neural nets here\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "print('LogisticRegression LogLoss {score}'.format(score=log_loss(y_test, logreg.predict_proba(X_test))))\n",
    "clfs.append(logreg)\n",
    "\n",
    "rfc2 = RandomForestClassifier(n_estimators=50, random_state=1337, n_jobs=-1)\n",
    "rfc2.fit(X_train, y_train)\n",
    "print('RFC2 LogLoss {score}'.format(score=log_loss(y_test, rfc2.predict_proba(X_test))))\n",
    "clfs.append(rfc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "### finding the optimum weights\n",
    "\n",
    "predictions = []\n",
    "for clf in clfs:\n",
    "    predictions.append(clf.predict_proba(X_test))\n",
    "\n",
    "def log_loss_func(weights):\n",
    "    ''' scipy minimize will pass the weights as a numpy array '''\n",
    "    final_prediction = 0\n",
    "    for weight, prediction in zip(weights, predictions):\n",
    "            final_prediction += weight*prediction\n",
    "\n",
    "    return log_loss(y_test, final_prediction)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting values : {starting_values} [0.5, 0.5, 0.5]\n",
      "Constraints: {cons} {'type': 'eq', 'fun': <function <lambda> at 0x19D1F6F0>}\n",
      "Bounds: {bounds} [(0, 1), (0, 1), (0, 1)]\n",
      "Ensamble Score: 0.5796827721549798\n",
      "Best Weights: [0.24765056 0.50836595 0.24398349]\n"
     ]
    }
   ],
   "source": [
    "#the algorithms need a starting value, right not we chose 0.5 for all weights\n",
    "#its better to choose many random starting points and run minimize a few times\n",
    "starting_values = [0.5]*len(predictions)\n",
    "print('Starting values : {starting_values}', starting_values)\n",
    "\n",
    "#adding constraints  and a different solver as suggested by user 16universe\n",
    "#https://kaggle2.blob.core.windows.net/forum-message-attachments/75655/2393/otto%20model%20weights.pdf?sv=2012-02-12&se=2015-05-03T21%3A22%3A17Z&sr=b&sp=r&sig=rkeA7EJC%2BiQ%2FJ%2BcMpcA4lYQLFh6ubNqs2XAkGtFsAv0%3D\n",
    "cons = ({'type':'eq','fun':lambda w: 1-sum(w)})\n",
    "print('Constraints: {cons}',cons)\n",
    "#our weights are bound between 0 and 1\n",
    "bounds = [(0,1)]*len(predictions)\n",
    "print('Bounds: {bounds}',bounds)\n",
    "#Minimize a scalar function of one or more variables using Sequential Least Squares Programming (SLSQP)\n",
    "\n",
    "res = minimize(log_loss_func, starting_values, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "\n",
    "print('Ensamble Score: {best_score}'.format(best_score=res['fun']))\n",
    "print('Best Weights: {weights}'.format(weights=res['x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
