{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Analysis Case Study\n",
    "## Part 1 : Graphics Analysis\n",
    "## Part 2 : Feature Reduction (Extraction/Selection)\n",
    "## Part 3 : Model Selection and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : Graphics Analysis\n",
    "\n",
    "In this case study, as part of phase I, we will perform exploratory data analysis by graphing the features in the dataset.\n",
    "\n",
    "The dataset is composed of 10,000 customer's record at a bank. The dataset has a total of 14 features 13 of which can be considered as independent variables and 1 as the dependent variable. The goal is to build a  model that can predict whether a customer is likely to stay or exit the bank. The model will predict the dependent variable 'Exited' using the approrpiate set of independent variables 'CreditScore','Geography','Gender','Age','Tenure','Balance','NumberOfProducts','HasCrCard', and 'IsActiveMember'.\n",
    "\n",
    "We will perform model selection and model validation exercises and use the model the make the desired prediction. The accuracy and percision of the model will be analyzed in the next phases of the study.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Step 1:  Load data into a dataframe\n",
    "DataFile = \"Data/BankCustomers.xlsx\"\n",
    "\n",
    "data = pd.read_excel(DataFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2:  check the dimension of the table\n",
    "print(\"The dimension of the table is: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Step 3:  Look at the data\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Step 5:  what type of variables are in the table \n",
    "print(\"Describe Data\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Step 6a: Summary of object type data\n",
    "print(\"Summarized Data\")\n",
    "print(data.describe(include=['O']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Step 6b: Summary of numeric type data\n",
    "print(\"Summarized Data\")\n",
    "print(data.describe(include=np.number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of ['Age', 'HasCrCard', 'IsActiveMember', 'Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set up the figure size\n",
    "plt.rcParams['figure.figsize'] = (20, 10)\n",
    "\n",
    "# make subplots\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = 2)\n",
    "\n",
    "# Specify the features of interest\n",
    "num_features = ['Age', 'HasCrCard', 'IsActiveMember', 'Exited']\n",
    "xaxes = num_features\n",
    "yaxes = ['Counts', 'Counts', 'Counts', 'Counts']\n",
    "\n",
    "# draw histograms\n",
    "axes = axes.ravel()\n",
    "for idx, ax in enumerate(axes):\n",
    "    ax.hist(data[num_features[idx]].dropna(), bins=50)\n",
    "    ax.set_xlabel(xaxes[idx], fontsize=20)\n",
    "    ax.set_ylabel(yaxes[idx], fontsize=20)\n",
    "    ax.tick_params(axis='both', labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Barchart comparing the number of:\n",
    "\n",
    "- **Exits vs stays**\n",
    "- **Males vs. Female**\n",
    "- **Has credit card vs does not have credit card**\n",
    "- **active members vs inactive members**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make subplots\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = 2)\n",
    "\n",
    "# make the data read to feed into the visulizer\n",
    "X_Exited = data.replace({'Exited': {1: 'Exited', 0: 'Stayed'}}).groupby('Exited').size().reset_index(name='Counts')['Exited']\n",
    "Y_Exited = data.replace({'Exited': {1: 'Exited', 0: 'Stayed'}}).groupby('Exited').size().reset_index(name='Counts')['Counts']\n",
    "# make the bar plot\n",
    "axes[0,0].bar(X_Exited, Y_Exited)\n",
    "axes[0,0].set_title('Exited/Stayed', fontsize=25)\n",
    "axes[0,0].set_ylabel('Counts', fontsize=20)\n",
    "axes[0,0].tick_params(axis='both', labelsize=15)\n",
    "\n",
    "# make the data read to feed into the visulizer\n",
    "X_Sex = data.groupby('Gender').size().reset_index(name='Counts')['Gender']\n",
    "Y_Sex = data.groupby('Gender').size().reset_index(name='Counts')['Counts']\n",
    "# make the bar plot\n",
    "axes[0,1].bar(X_Sex, Y_Sex)\n",
    "axes[0,1].set_title('Sex', fontsize=25)\n",
    "axes[0,1].set_ylabel('Counts', fontsize=20)\n",
    "axes[0,1].tick_params(axis='both', labelsize=15)\n",
    "\n",
    "X_HasCrCard = data.replace({'HasCrCard': {1: 'Credit Card', 0: 'No Credit Card'}}).groupby('HasCrCard').size().reset_index(name='Counts')['HasCrCard']\n",
    "Y_HasCrCard = data.replace({'HasCrCard': {1: 'Credit Card', 0: 'No Credit Card'}}).groupby('HasCrCard').size().reset_index(name='Counts')['Counts']\n",
    "# make the bar plot\n",
    "axes[1,0].bar(X_HasCrCard, Y_HasCrCard)\n",
    "axes[1,0].set_title('Credit Card', fontsize=25)\n",
    "axes[1,0].set_ylabel('Counts', fontsize=20)\n",
    "axes[1,0].tick_params(axis='both', labelsize=15)\n",
    "\n",
    "X_IsActive = data.replace({'IsActiveMember': {1: 'Active', 0: 'Inactive'}}).groupby('IsActiveMember').size().reset_index(name='Counts')['IsActiveMember']\n",
    "Y_IsActive = data.replace({'IsActiveMember': {1: 'Active', 0: 'Inactive'}}).groupby('IsActiveMember').size().reset_index(name='Counts')['Counts']\n",
    "# make the bar plot\n",
    "axes[1,1].bar(X_IsActive, Y_IsActive)\n",
    "axes[1,1].set_title('Acitivity', fontsize=25)\n",
    "axes[1,1].set_ylabel('Counts', fontsize=20)\n",
    "axes[1,1].tick_params(axis='both', labelsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Coordinate graphe comparing ['Age', 'CreditScore', 'Balance', 'EstimatedSalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Step 9:  Compare variables against those who stayed and those who exited\n",
    "#set up the figure size\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15, 7)\n",
    "plt.rcParams['font.size'] = 50\n",
    "\n",
    "# setup the color for yellowbrick visulizer\n",
    "from yellowbrick.style import set_palette\n",
    "set_palette('sns_bright')\n",
    "\n",
    "# import packages\n",
    "from yellowbrick.features import ParallelCoordinates\n",
    "# Specify the features of interest and the classes of the target\n",
    "classes = ['exited', 'stayed']\n",
    "num_features = ['Age', 'CreditScore', 'Balance', 'EstimatedSalary']\n",
    "\n",
    "# copy data to a new dataframe\n",
    "data_norm = data.copy()\n",
    "# normalize data to 0-1 range\n",
    "for feature in num_features:\n",
    "    data_norm[feature] = (data[feature] - data[feature].mean(skipna=True)) / (data[feature].max(skipna=True) - data[feature].min(skipna=True))\n",
    "\n",
    "# Extract the numpy arrays from the data frame\n",
    "X = data_norm[num_features].values\n",
    "y = data.Exited.values\n",
    "\n",
    "# Instantiate the visualizer\n",
    "# Instantiate the visualizer\n",
    "visualizer = ParallelCoordinates(classes=classes, features=num_features)\n",
    "\n",
    "\n",
    "visualizer.fit(X, y)      # Fit the data to the visualizer\n",
    "visualizer.transform(X)   # Transform the data\n",
    "visualizer.poof(outpath=\"images/pcoords2.png\") # Draw/show/poof the data\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked bar charts showing stays and exits based on:\n",
    "\n",
    "- **Gender**\n",
    "- **Has Credit card**\n",
    "- **banking activity**\n",
    "- **gegraphic location(Country)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Step 10 - stacked bar chart to compare Gender exit/stay numbers\n",
    "#set up the figure size\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (20, 20)\n",
    "\n",
    "# make subplots\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = 2)\n",
    "\n",
    "# make the data read to feed into the visulizer\n",
    "Gender_Stayed = data.replace({'Exited': {1: 'Exited', 0: 'Stayed'}})[data['Exited']==0]['Gender'].value_counts()\n",
    "Gender_Exited = data.replace({'Exited': {1: 'Exited', 0: 'Stayed'}})[data['Exited']==1]['Gender'].value_counts()\n",
    "Gender_Exited = Gender_Exited.reindex(index = Gender_Stayed.index)\n",
    "# make the bar plot\n",
    "p1 = axes[0, 0].bar(Gender_Stayed.index, Gender_Stayed.values)\n",
    "p2 = axes[0, 0].bar(Gender_Exited.index, Gender_Exited.values, bottom=Gender_Stayed.values)\n",
    "axes[0, 0].set_title('Gender Stayed/Exited', fontsize=25)\n",
    "axes[0, 0].set_ylabel('Counts', fontsize=20)\n",
    "axes[0, 0].tick_params(axis='both', labelsize=15)\n",
    "axes[0, 0].legend((p1[0], p2[0]), ('Stayed', 'Exited'), fontsize = 15)\n",
    "\n",
    "# make the data read to feed into the visulizer\n",
    "HasCrCard_Stayed = data.replace({'Exited': {1: 'Exited', 0: 'Stayed'}})[data['Exited']==0]\n",
    "HasCrCard_Stayed = HasCrCard_Stayed.replace({'HasCrCard': {1: 'CreditCard', 0: 'No CreditCard'}})['HasCrCard'].value_counts()\n",
    "\n",
    "HasCrCard_Exited = data.replace({'Exited': {1: 'Exited', 0: 'Stayed'}})[data['Exited']==1]\n",
    "HasCrCard_Exited = HasCrCard_Exited.replace({'HasCrCard': {1: 'CreditCard', 0: 'No CreditCard'}})['HasCrCard'].value_counts()\n",
    "HasCrCard_Exited = HasCrCard_Exited.reindex(index = HasCrCard_Stayed.index)\n",
    "# make the bar plot\n",
    "p3 = axes[0, 1].bar(HasCrCard_Stayed.index, HasCrCard_Stayed.values)\n",
    "p4 = axes[0, 1].bar(HasCrCard_Exited.index, HasCrCard_Exited.values, bottom=HasCrCard_Stayed.values)\n",
    "axes[0, 1].set_title('HasCrCard Stayed/Exited', fontsize=25)\n",
    "axes[0, 1].set_ylabel('Counts', fontsize=20)\n",
    "axes[0, 1].tick_params(axis='both', labelsize=15)\n",
    "axes[0, 1].legend((p3[0], p4[0]), ('Stayed', 'Exited'), fontsize = 15)\n",
    "\n",
    "# make the data read to feed into the visulizer\n",
    "IsActive_Stayed = data.replace({'Exited': {1: 'Exited', 0: 'Stayed'}})[data['Exited']==0]\n",
    "IsActive_Stayed = IsActive_Stayed.replace({'IsActiveMember': {1: 'Active', 0: 'Inactive'}})['IsActiveMember'].value_counts()\n",
    "\n",
    "IsActive_Exited = data.replace({'Exited': {1: 'Exited', 0: 'Stayed'}})[data['Exited']==1]\n",
    "IsActive_Exited = IsActive_Exited.replace({'IsActiveMember': {1: 'Active', 0: 'Inactive'}})['IsActiveMember'].value_counts()\n",
    "IsActive_Exited = IsActive_Exited.reindex(index = IsActive_Stayed.index)\n",
    "# make the bar plot\n",
    "p4 = axes[1,0].bar(IsActive_Stayed.index, IsActive_Stayed.values)\n",
    "p5 = axes[1,0].bar(IsActive_Exited.index, IsActive_Exited.values, bottom=IsActive_Stayed.values)\n",
    "axes[1,0].set_title('Active/Inactive Stayed/Exited', fontsize=25)\n",
    "axes[1,0].set_ylabel('Counts', fontsize=20)\n",
    "axes[1,0].tick_params(axis='both', labelsize=15)\n",
    "axes[1,0].legend((p4[0], p5[0]), ('Stayed', 'Exited'), fontsize = 15)\n",
    "\n",
    "\n",
    "# make the data read to feed into the visulizer\n",
    "Country_Stayed = data.replace({'Exited': {1: 'Exited', 0: 'Stayed'}})[data['Exited']==0]['Geography'].value_counts()\n",
    "\n",
    "Country_Exited = data.replace({'Exited': {1: 'Exited', 0: 'Stayed'}})[data['Exited']==1]['Geography'].value_counts()\n",
    "Country_Exited = Country_Exited.reindex(index = Country_Stayed.index)\n",
    "# make the bar plot\n",
    "p6 = axes[1,1].bar(Country_Stayed.index, Country_Stayed.values)\n",
    "p7 = axes[1,1].bar(Country_Exited.index, Country_Exited.values, bottom=Country_Stayed.values)\n",
    "axes[1,1].set_title('Countries Stayed/Exited', fontsize=25)\n",
    "axes[1,1].set_ylabel('Counts', fontsize=20)\n",
    "axes[1,1].tick_params(axis='both', labelsize=15)\n",
    "axes[1,1].legend((p6[0], p7[0]),('Stayed', 'Exited'), fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Feature Reduction (Extraction/Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Step 1:  Load data into a dataframe\n",
    "DataFile = \"Data/BankCustomers.xlsx\"\n",
    "\n",
    "data = pd.read_excel(DataFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Step 11- remove unrelated columns\n",
    "data = data.drop(['RowNumber','CustomerId','Surname'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Step 12 - Onehot code Geography\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
    "\n",
    "feature = np.array(data['Geography'])\n",
    "one_hot = LabelBinarizer()\n",
    "\n",
    "one_hot.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "one_hot.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(feature)\n",
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Drop Geography column\n",
    "data = data.drop(['Geography'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Add dummies\n",
    "data[dummies.columns] = dummies\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# one-hot code Gender\n",
    "feature = np.array(data['Gender'])\n",
    "one_hot = LabelBinarizer()\n",
    "\n",
    "one_hot.fit_transform(feature)\n",
    "dummies = pd.get_dummies(feature)\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " #drop Gender and add dummies\n",
    "data = data.drop(['Gender'],axis=1)\n",
    "data[dummies.columns] = dummies\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Drop spain and male to avoid dummy trap\n",
    "data = data.drop(['Male','Spain'],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Move the dependent variable column to the last position.\n",
    "\n",
    "Exited = data.replace({'Exited': {1: 'Existed', 0: 'Stayed'}})['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data.drop(['Exited'],axis=1)\n",
    "data['Exited'] = Exited\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Step 13 - Set up independet variable and depndent variables and perform feature reduction\n",
    "Independents = data.iloc[:, :-1].values\n",
    "print(type(Independents))\n",
    "Dependent = data.iloc[:,-1].values\n",
    "print(Dependent)\n",
    "X = Independents\n",
    "y = Dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Attempt at feature reduction using PCA Before feature scaling\n",
    "#Load libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a PCA that will retain 99% of variance\n",
    "pca = PCA(n_components=0.99, whiten=True)\n",
    "\n",
    "# Conduct PCA\n",
    "features_pca = pca.fit_transform(X)\n",
    "\n",
    "# Show results\n",
    "print(\"Original number of features:\", X.shape[1])\n",
    "print(\"Reduced number of features:\", features_pca.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Feature scaling will normalize all variable to the same scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Attempt at feature reduction using PCA After feature scaling\n",
    "#Load libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a PCA that will retain 99% of variance\n",
    "pca = PCA(n_components=0.99, whiten=True)\n",
    "\n",
    "# Conduct PCA\n",
    "features_pca = pca.fit_transform(X)\n",
    "\n",
    "# Show results\n",
    "print(\"Original number of features:\", X.shape[1])\n",
    "print(\"Reduced number of features:\", features_pca.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 : Model Selection and Evaluation\n",
    "\n",
    "Summary of parts1 1 and 2:\n",
    "We have performed feature reduction and scaled the independent variables. The X and y variables are the independent variables dataset and the dependent variables respectively. The value of 0 or 1 for the depended variable has been converted to 'Stayed' and 'Exited\" respectively in anticipation of using logistic regression classifier for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yellowbrick\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Indpendent variables matrix:\\n\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Dependent variable array:\\n\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14 - Split the dataset to 30% test set and 70% training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.3, random_state=0)\n",
    "\n",
    "# number of samples in each set\n",
    "print(\"Total sample in dataset: \", X.shape[0])\n",
    "\n",
    "print(\"No. of samples in training set: \", X_train.shape[0])\n",
    "print(\"No. of samples in validation set:\", X_test.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# stayed and exited\n",
    "print('\\n')\n",
    "print('No. of customer who stayed and exited in the training set:')\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\n')\n",
    "print('No. of customer who stayed and exited  in the validation set:')\n",
    "print(pd.Series(y_val).value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15  - Model evaluation and metrics\n",
    "\n",
    "#### Create a logistics regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.classifier import ROCAUC  \n",
    "\n",
    "# Instantiate the classification model\n",
    "model = LogisticRegression()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define class for 'Exited' and 'stayed' to create confusion metrix and fit it into the trainign sets. Then display the confusion metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#The ConfusionMatrix visualizer taxes a model\n",
    "classes = ['Exited','Stayed']\n",
    "cm = ConfusionMatrix(model, classes=classes, percent=False)\n",
    "\n",
    "#Fit fits the passed model. This is unnecessary if you pass the visualizer a pre-fitted model\n",
    "cm.fit(X_train, y_train)\n",
    "\n",
    "#To create the ConfusionMatrix, we need some test data. Score runs predict() on the data\n",
    "#and then creates the confusion_matrix from scikit learn.\n",
    "cm.score(X_val, y_val)\n",
    "\n",
    "# change fontsize of the labels in the figure\n",
    "for label in cm.ax.texts:\n",
    "    label.set_size(20)\n",
    "\n",
    "#How did we do?\n",
    "cm.poof()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision, Recall, and F1 Score metrics:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15, 7)\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "# Instantiate the visualizer\n",
    "visualizer = ClassificationReport(model, classes=classes)\n",
    "\n",
    "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(X_val, y_val)  # Evaluate the model on the test data\n",
    "g = visualizer.poof()\n",
    "\n",
    "# ROC and AUC\n",
    "#Instantiate the visualizer\n",
    "visualizer = ROCAUC(model)\n",
    "\n",
    "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(X_val, y_val)  # Evaluate the model on the test data\n",
    "g = visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#Step 1:  Load data into a dataframe\n",
    "DataFile = \"Data/BankCustomers.xlsx\"\n",
    "\n",
    "dataset = pd.read_excel(DataFile)\n",
    "print(dataset.shape)\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# One Hot Encoding the \"Geography\" column\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create trainig and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initislize an ANN\n",
    "import tensorflow as tf\n",
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Add the input layer and the first hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Add output layer\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Cimpile\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train on training set\n",
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Making prediction using test set\n",
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# making confusion matrix to detrmine accuracy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training XGBoost on the Training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 14)\n"
     ]
    }
   ],
   "source": [
    "#Step 1:  Load data into a dataframe\n",
    "DataFile = \"Data/BankCustomers.xlsx\"\n",
    "\n",
    "dataset = pd.read_excel(DataFile)\n",
    "print(dataset.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
      "0             619    France  Female   42       2       0.00              1   \n",
      "1             608     Spain  Female   41       1   83807.86              1   \n",
      "2             502    France  Female   42       8  159660.80              3   \n",
      "3             699    France  Female   39       1       0.00              2   \n",
      "4             850     Spain  Female   43       2  125510.82              1   \n",
      "...           ...       ...     ...  ...     ...        ...            ...   \n",
      "9995          771    France    Male   39       5       0.00              2   \n",
      "9996          516    France    Male   35      10   57369.61              1   \n",
      "9997          709    France  Female   36       7       0.00              1   \n",
      "9998          772   Germany    Male   42       3   75075.31              2   \n",
      "9999          792    France  Female   28       4  130142.79              1   \n",
      "\n",
      "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
      "0             1               1        101348.88  \n",
      "1             0               1        112542.58  \n",
      "2             1               0        113931.57  \n",
      "3             0               0         93826.63  \n",
      "4             1               1         79084.10  \n",
      "...         ...             ...              ...  \n",
      "9995          1               0         96270.64  \n",
      "9996          1               1        101699.77  \n",
      "9997          0               1         42085.58  \n",
      "9998          1               0         92888.52  \n",
      "9999          1               0         38190.78  \n",
      "\n",
      "[10000 rows x 10 columns]\n",
      "0       1\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9995    0\n",
      "9996    0\n",
      "9997    1\n",
      "9998    1\n",
      "9999    0\n",
      "Name: Exited, Length: 10000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset.iloc[:, 3:-1])\n",
    "print(dataset.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 3:-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' ... 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
      " [502 'France' 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 'Female' ... 0 1 42085.58]\n",
      " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
      " [792 'France' 'Female' ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 3:-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' ... 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
      " [502 'France' 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 'Female' ... 0 1 42085.58]\n",
      " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
      " [792 'France' 'Female' ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding the \"Gender\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 0 ... 1 1 101348.88]\n",
      " [608 'Spain' 0 ... 0 1 112542.58]\n",
      " [502 'France' 0 ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 0 ... 0 1 42085.58]\n",
      " [772 'Germany' 1 ... 1 0 92888.52]\n",
      " [792 'France' 0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding the \"Geography\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
      " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
      " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
      " ...\n",
      " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
      " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
      " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 ... 1 0 163830.64]\n",
      " [0.0 1.0 0.0 ... 1 1 57098.0]\n",
      " [1.0 0.0 0.0 ... 1 0 185630.76]\n",
      " ...\n",
      " [1.0 0.0 0.0 ... 1 0 181429.87]\n",
      " [0.0 0.0 1.0 ... 1 1 148750.16]\n",
      " [0.0 1.0 0.0 ... 1 0 118855.26]] [0 0 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "print(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training XGBoost on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'base_score'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc550\\week9and10\\venv\\lib\\site-packages\\IPython\\core\\formatters.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, obj, include, exclude)\u001B[0m\n\u001B[0;32m    968\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    969\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mmethod\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 970\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minclude\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minclude\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mexclude\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mexclude\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    971\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    972\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc550\\week9and10\\venv\\lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36m_repr_mimebundle_\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    461\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_repr_mimebundle_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    462\u001B[0m         \u001B[1;34m\"\"\"Mime bundle used by jupyter kernels to display estimator\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 463\u001B[1;33m         \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m\"text/plain\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mrepr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    464\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mget_config\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"display\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'diagram'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    465\u001B[0m             \u001B[0moutput\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"text/html\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mestimator_html_repr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc550\\week9and10\\venv\\lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36m__repr__\u001B[1;34m(self, N_CHAR_MAX)\u001B[0m\n\u001B[0;32m    277\u001B[0m             n_max_elements_to_show=N_MAX_ELEMENTS_TO_SHOW)\n\u001B[0;32m    278\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 279\u001B[1;33m         \u001B[0mrepr_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    280\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    281\u001B[0m         \u001B[1;31m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\pprint.py\u001B[0m in \u001B[0;36mpformat\u001B[1;34m(self, object)\u001B[0m\n\u001B[0;32m    142\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mpformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    143\u001B[0m         \u001B[0msio\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_StringIO\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 144\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_format\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobject\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msio\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    145\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0msio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgetvalue\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    146\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\pprint.py\u001B[0m in \u001B[0;36m_format\u001B[1;34m(self, object, stream, indent, allowance, context, level)\u001B[0m\n\u001B[0;32m    159\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_readable\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    160\u001B[0m             \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 161\u001B[1;33m         \u001B[0mrep\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_repr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobject\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    162\u001B[0m         \u001B[0mmax_width\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_width\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mindent\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mallowance\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    163\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrep\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[0mmax_width\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\pprint.py\u001B[0m in \u001B[0;36m_repr\u001B[1;34m(self, object, context, level)\u001B[0m\n\u001B[0;32m    391\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_repr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    392\u001B[0m         repr, readable, recursive = self.format(object, context.copy(),\n\u001B[1;32m--> 393\u001B[1;33m                                                 self._depth, level)\n\u001B[0m\u001B[0;32m    394\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mreadable\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    395\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_readable\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc550\\week9and10\\venv\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001B[0m in \u001B[0;36mformat\u001B[1;34m(self, object, context, maxlevels, level)\u001B[0m\n\u001B[0;32m    168\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmaxlevels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    169\u001B[0m         return _safe_repr(object, context, maxlevels, level,\n\u001B[1;32m--> 170\u001B[1;33m                           changed_only=self._changed_only)\n\u001B[0m\u001B[0;32m    171\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    172\u001B[0m     def _pprint_estimator(self, object, stream, indent, allowance, context,\n",
      "\u001B[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc550\\week9and10\\venv\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001B[0m in \u001B[0;36m_safe_repr\u001B[1;34m(object, context, maxlevels, level, changed_only)\u001B[0m\n\u001B[0;32m    412\u001B[0m         \u001B[0mrecursive\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    413\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mchanged_only\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 414\u001B[1;33m             \u001B[0mparams\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_changed_params\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobject\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    415\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    416\u001B[0m             \u001B[0mparams\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_params\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdeep\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc550\\week9and10\\venv\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001B[0m in \u001B[0;36m_changed_params\u001B[1;34m(estimator)\u001B[0m\n\u001B[0;32m     96\u001B[0m     \u001B[0minit_params\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mparam\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdefault\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparam\u001B[0m \u001B[1;32min\u001B[0m \u001B[0minit_params\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     97\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 98\u001B[1;33m         if (repr(v) != repr(init_params[k]) and\n\u001B[0m\u001B[0;32m     99\u001B[0m                 not (is_scalar_nan(init_params[k]) and is_scalar_nan(v))):\n\u001B[0;32m    100\u001B[0m             \u001B[0mfiltered_params\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mv\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'base_score'"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'base_score'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc550\\week9and10\\venv\\lib\\site-packages\\IPython\\core\\formatters.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, obj)\u001B[0m\n\u001B[0;32m    700\u001B[0m                 \u001B[0mtype_pprinters\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtype_printers\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    701\u001B[0m                 deferred_pprinters=self.deferred_printers)\n\u001B[1;32m--> 702\u001B[1;33m             \u001B[0mprinter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpretty\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    703\u001B[0m             \u001B[0mprinter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflush\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    704\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mstream\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgetvalue\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc550\\week9and10\\venv\\lib\\site-packages\\IPython\\lib\\pretty.py\u001B[0m in \u001B[0;36mpretty\u001B[1;34m(self, obj)\u001B[0m\n\u001B[0;32m    392\u001B[0m                         \u001B[1;32mif\u001B[0m \u001B[0mcls\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    393\u001B[0m                                 \u001B[1;32mand\u001B[0m \u001B[0mcallable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcls\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__dict__\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'__repr__'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 394\u001B[1;33m                             \u001B[1;32mreturn\u001B[0m \u001B[0m_repr_pprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcycle\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    395\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    396\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0m_default_pprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcycle\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc550\\week9and10\\venv\\lib\\site-packages\\IPython\\lib\\pretty.py\u001B[0m in \u001B[0;36m_repr_pprint\u001B[1;34m(obj, p, cycle)\u001B[0m\n\u001B[0;32m    698\u001B[0m     \u001B[1;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    699\u001B[0m     \u001B[1;31m# Find newlines and replace them with p.break_()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 700\u001B[1;33m     \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrepr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    701\u001B[0m     \u001B[0mlines\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moutput\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplitlines\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    702\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgroup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc550\\week9and10\\venv\\lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36m__repr__\u001B[1;34m(self, N_CHAR_MAX)\u001B[0m\n\u001B[0;32m    277\u001B[0m             n_max_elements_to_show=N_MAX_ELEMENTS_TO_SHOW)\n\u001B[0;32m    278\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 279\u001B[1;33m         \u001B[0mrepr_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    280\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    281\u001B[0m         \u001B[1;31m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\pprint.py\u001B[0m in \u001B[0;36mpformat\u001B[1;34m(self, object)\u001B[0m\n\u001B[0;32m    142\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mpformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    143\u001B[0m         \u001B[0msio\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_StringIO\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 144\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_format\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobject\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msio\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    145\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0msio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgetvalue\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    146\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\pprint.py\u001B[0m in \u001B[0;36m_format\u001B[1;34m(self, object, stream, indent, allowance, context, level)\u001B[0m\n\u001B[0;32m    159\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_readable\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    160\u001B[0m             \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 161\u001B[1;33m         \u001B[0mrep\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_repr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobject\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    162\u001B[0m         \u001B[0mmax_width\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_width\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mindent\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mallowance\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    163\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrep\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[0mmax_width\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\pprint.py\u001B[0m in \u001B[0;36m_repr\u001B[1;34m(self, object, context, level)\u001B[0m\n\u001B[0;32m    391\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_repr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    392\u001B[0m         repr, readable, recursive = self.format(object, context.copy(),\n\u001B[1;32m--> 393\u001B[1;33m                                                 self._depth, level)\n\u001B[0m\u001B[0;32m    394\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mreadable\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    395\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_readable\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc550\\week9and10\\venv\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001B[0m in \u001B[0;36mformat\u001B[1;34m(self, object, context, maxlevels, level)\u001B[0m\n\u001B[0;32m    168\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmaxlevels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    169\u001B[0m         return _safe_repr(object, context, maxlevels, level,\n\u001B[1;32m--> 170\u001B[1;33m                           changed_only=self._changed_only)\n\u001B[0m\u001B[0;32m    171\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    172\u001B[0m     def _pprint_estimator(self, object, stream, indent, allowance, context,\n",
      "\u001B[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc550\\week9and10\\venv\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001B[0m in \u001B[0;36m_safe_repr\u001B[1;34m(object, context, maxlevels, level, changed_only)\u001B[0m\n\u001B[0;32m    412\u001B[0m         \u001B[0mrecursive\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    413\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mchanged_only\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 414\u001B[1;33m             \u001B[0mparams\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_changed_params\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobject\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    415\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    416\u001B[0m             \u001B[0mparams\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_params\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdeep\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc550\\week9and10\\venv\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001B[0m in \u001B[0;36m_changed_params\u001B[1;34m(estimator)\u001B[0m\n\u001B[0;32m     96\u001B[0m     \u001B[0minit_params\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mparam\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdefault\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparam\u001B[0m \u001B[1;32min\u001B[0m \u001B[0minit_params\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     97\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 98\u001B[1;33m         if (repr(v) != repr(init_params[k]) and\n\u001B[0m\u001B[0;32m     99\u001B[0m                 not (is_scalar_nan(init_params[k]) and is_scalar_nan(v))):\n\u001B[0;32m    100\u001B[0m             \u001B[0mfiltered_params\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mv\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'base_score'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
    "              min_child_weight=1, missing=np.nan, monotone_constraints='()',\n",
    "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
    "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}