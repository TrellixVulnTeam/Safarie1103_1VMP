{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python – Binomial Distribution\n",
    "Last Updated: 16-07-2020\n",
    "\n",
    "**Binomial distribution** is a probability distribution that summarises the likelihood that a variable will take one of two independent values under a given set of parameters. The distribution is obtained by performing a number of **Bernoulli** trials.\n",
    "\n",
    "A Bernoulli trial is assumed to meet each of these criteria :\n",
    "\n",
    "- There must be only 2 possible outcomes.\n",
    "- Each outcome has a fixed probability of occurring. A success has the probability of p, and a failure has the probability of 1 – p.\n",
    "- Each trial is completely independent of all others.\n",
    "\n",
    "The binomial random variable represents the number of successes(r) in n successive independent trials of a Bernoulli experiment.\n",
    "\n",
    "Probability of achieving r success and n-r failure is :\n",
    "\n",
    "$$p^r * (1-p)^{n-r}$$\n",
    "\n",
    "The number of ways we can achieve r successes is : \n",
    "\n",
    "$$\\frac{n!}{(n-r)!\\ *\\ r!}$$\n",
    "\n",
    "Hence, the probability mass function(pmf), which is the total probability of achieving r success and n-r failure is :\n",
    "\n",
    "$$\\frac{n!}{(n-r)!\\ *\\ r!}\\ *\\ p^r * (1-p)^{n-r}$$\n",
    "\n",
    "An example illustrating the distribution :\n",
    "Consider a random experiment of tossing a biased coin 6 times where the probability of getting a head is 0.6. If ‘getting a head’ is considered as ‘success’ then, the binomial distribution table will contain the probability of r successes for each possible value of r.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/voting-ensembles-with-python/#:~:text=A%20voting%20ensemble%20(or%20a,model%20used%20in%20the%20ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom \n",
    "# setting the values \n",
    "# of n and p \n",
    "n = 1000 # Number of trials\n",
    "p = 0.5 # Probability of success\n",
    "\n",
    "# defining the list of r values \n",
    "r_values = list(range(n + 1)) \n",
    "\n",
    "print(r_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.0 250.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# obtaining the mean and variance  \n",
    "mean, var = binom.stats(n, p) \n",
    "print(mean,var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r\tp(r)\n",
      "0\t9.332636185032827e-302\n",
      "1\t9.332636185042109e-299\n",
      "2\t4.661651774421211e-296\n",
      "3\t1.5507761569596102e-293\n",
      "4\t3.8653095712193346e-291\n",
      "5\t7.69969666587513e-289\n",
      "6\t1.276866363757387e-286\n",
      "7\t1.813150236534654e-284\n",
      "8\t2.250572731097086e-282\n",
      "9\t2.480631276944899e-280\n",
      "10\t2.4583055954488076e-278\n",
      "11\t2.2124750359081712e-276\n",
      "12\t1.8234481754254712e-274\n",
      "13\t1.3858206133234934e-272\n",
      "14\t9.77003532393424e-271\n",
      "15\t6.422169886269788e-269\n",
      "16\t3.9536483362325125e-267\n",
      "17\t2.2884646840329276e-265\n",
      "18\t1.2497559913345134e-263\n",
      "19\t6.459265176273511e-262\n",
      "20\t3.168269568958367e-260\n",
      "21\t1.4785257988488824e-258\n",
      "22\t6.579439804871213e-257\n",
      "23\t2.7976922300694073e-255\n",
      "24\t1.1388938786592774e-253\n",
      "25\t4.446241702283881e-252\n",
      "26\t1.667340638354704e-250\n",
      "27\t6.014776969480499e-249\n",
      "28\t2.090134996892055e-247\n",
      "29\t7.00555592061954e-246\n",
      "30\t2.2674649329717145e-244\n",
      "31\t7.094970919310955e-243\n",
      "32\t2.148445881502688e-241\n",
      "33\t6.302107919080122e-240\n",
      "34\t1.7923936346315775e-238\n",
      "35\t4.947006431585211e-237\n",
      "36\t1.326072557354974e-235\n",
      "37\t3.4549566088927274e-234\n",
      "38\t8.755587406212193e-233\n",
      "39\t2.1597115601998176e-231\n",
      "40\t5.188707023377908e-230\n",
      "41\t1.2149167664500524e-228\n",
      "42\t2.7740599500608837e-227\n",
      "43\t6.180347516653937e-226\n",
      "44\t1.344225584870753e-224\n",
      "45\t2.8557325758595582e-223\n",
      "46\t5.928749152053135e-222\n",
      "47\t1.2034099342680146e-220\n",
      "48\t2.3892701403284227e-219\n",
      "49\t4.64201055835302e-218\n",
      "50\t8.829104081983372e-217\n",
      "51\t1.644637034878066e-215\n",
      "52\t3.001462588654405e-214\n",
      "53\t5.368653837826157e-213\n",
      "54\t9.415028119287134e-212\n",
      "55\t1.6193848365180408e-210\n",
      "56\t2.7327119116219533e-209\n",
      "57\t4.525754464167747e-208\n",
      "58\t7.358252516732383e-207\n",
      "59\t1.1748260797903825e-205\n",
      "60\t1.842518901805357e-204\n",
      "61\t2.8392914224526464e-203\n",
      "62\t4.30015265433003e-202\n",
      "63\t6.4024495075534626e-201\n",
      "64\t9.373586232155349e-200\n",
      "65\t1.3497964174315378e-198\n",
      "66\t1.9122115913601338e-197\n",
      "67\t2.6656800393006e-196\n",
      "68\t3.657469818625176e-195\n",
      "69\t4.940234595590159e-194\n",
      "70\t6.570512012138078e-193\n",
      "71\t8.606445311678335e-192\n",
      "72\t1.110470513131119e-190\n",
      "73\t1.411666624912251e-189\n",
      "74\t1.7683985963432495e-188\n",
      "75\t2.183382800283159e-187\n",
      "76\t2.6574066977137204e-186\n",
      "77\t3.188888037257375e-185\n",
      "78\t3.773517510755176e-184\n",
      "79\t4.404029297359562e-183\n",
      "80\t5.0701387285890386e-182\n",
      "81\t5.758676086787967e-181\n",
      "82\t6.453930882635363e-180\n",
      "83\t7.138203072600704e-179\n",
      "84\t7.792538354260391e-178\n",
      "85\t8.397606038238342e-177\n",
      "86\t8.934662238360092e-176\n",
      "87\t9.386530213629113e-175\n",
      "88\t9.738525096633494e-174\n",
      "89\t9.979252683309768e-173\n",
      "90\t1.0101221327210248e-171\n",
      "91\t1.0101221327204984e-170\n",
      "92\t9.980445854806528e-170\n",
      "93\t9.744349286203819e-169\n",
      "94\t9.402260428286516e-168\n",
      "95\t8.966787313714899e-167\n",
      "96\t8.453065123870979e-166\n",
      "97\t7.877908115440199e-165\n",
      "98\t7.258929620647828e-164\n",
      "99\t6.613691432145614e-163\n",
      "100\t5.958935980367618e-162\n",
      "101\t5.309942952802027e-161\n",
      "102\t4.680037955463554e-160\n",
      "103\t4.080266100970546e-159\n",
      "104\t3.5192295120898933e-158\n",
      "105\t3.003075850317302e-157\n",
      "106\t2.535615930219836e-156\n",
      "107\t2.118542655716232e-155\n",
      "108\t1.7517209181074295e-154\n",
      "109\t1.433518402706739e-153\n",
      "110\t1.161149906192459e-152\n",
      "111\t9.310120869468689e-152\n",
      "112\t7.389908440145743e-151\n",
      "113\t5.80729088039343e-150\n",
      "114\t4.518479834131088e-149\n",
      "115\t3.4811940287352815e-148\n",
      "116\t2.655910961575953e-147\n",
      "117\t2.006688282079175e-146\n",
      "118\t1.5016150449798852e-145\n",
      "119\t1.1129617392204209e-144\n",
      "120\t8.17099410210667e-144\n",
      "121\t5.9425411651673125e-143\n",
      "122\t4.2815522001558204e-142\n",
      "123\t3.056262464825165e-141\n",
      "124\t2.1615662755245913e-140\n",
      "125\t1.5148256458871195e-139\n",
      "126\t1.0519622540880649e-138\n",
      "127\t7.239488268296378e-138\n",
      "128\t4.937557232987584e-137\n",
      "129\t3.3376355869499697e-136\n",
      "130\t2.2362158432550125e-135\n",
      "131\t1.485120445519921e-134\n",
      "132\t9.77704293300069e-134\n",
      "133\t6.380806966803246e-133\n",
      "134\t4.128477343450035e-132\n",
      "135\t2.6483417625378945e-131\n",
      "136\t1.684423253380083e-130\n",
      "137\t1.0622932050510481e-129\n",
      "138\t6.64318141999583e-129\n",
      "139\t4.1197283338351995e-128\n",
      "140\t2.533632925310158e-127\n",
      "141\t1.5453363941599443e-126\n",
      "142\t9.348196919601548e-126\n",
      "143\t5.608918151761245e-125\n",
      "144\t3.3380853167077657e-124\n",
      "145\t1.9706214007605794e-123\n",
      "146\t1.1540282860619729e-122\n",
      "147\t6.704354804735351e-122\n",
      "148\t3.8640639516521104e-121\n",
      "149\t2.2095184475225795e-120\n",
      "150\t1.2535334658923432e-119\n",
      "151\t7.056314211981571e-119\n",
      "152\t3.941322872349838e-118\n",
      "153\t2.1844717619309415e-117\n",
      "154\t1.2014594690618387e-116\n",
      "155\t6.557643295653808e-116\n",
      "156\t3.552056785147053e-115\n",
      "157\t1.9095133290835325e-114\n",
      "158\t1.0188099597583116e-113\n",
      "159\t5.3952074598575e-113\n",
      "160\t2.835855921086076e-112\n",
      "161\t1.4795770023057562e-111\n",
      "162\t7.66274756131675e-111\n",
      "163\t3.9394984395007266e-110\n",
      "164\t2.0105854840628e-109\n",
      "165\t1.0186966452583672e-108\n",
      "166\t5.124166860186999e-108\n",
      "167\t2.5590150667017198e-107\n",
      "168\t1.2688449705731273e-106\n",
      "169\t6.246621393593915e-106\n",
      "170\t3.0534955165149037e-105\n",
      "171\t1.482106010942614e-104\n",
      "172\t7.143406296915858e-104\n",
      "173\t3.4189250947122066e-103\n",
      "174\t1.6249718697267894e-102\n",
      "175\t7.669867225113302e-102\n",
      "176\t3.5952502617733777e-101\n",
      "177\t1.673721025818528e-100\n",
      "178\t7.738609012641132e-100\n",
      "179\t3.553707602449426e-99\n",
      "180\t1.620885523119251e-98\n",
      "181\t7.343238281533027e-98\n",
      "182\t3.3044572266883375e-97\n",
      "183\t1.4770743231857094e-96\n",
      "184\t6.558531098058769e-96\n",
      "185\t2.892843987036608e-95\n",
      "186\t1.2675633599103798e-94\n",
      "187\t5.51762874314479e-94\n",
      "188\t2.386080940518339e-93\n",
      "189\t1.0251310707405684e-92\n",
      "190\t4.375691044057743e-92\n",
      "191\t1.8556595527171244e-91\n",
      "192\t7.818898844515713e-91\n",
      "193\t3.27340428309182e-90\n",
      "194\t1.3616686888938344e-89\n",
      "195\t5.628230580770963e-89\n",
      "196\t2.3115947028120727e-88\n",
      "197\t9.4341225434646e-88\n",
      "198\t3.8260608092942925e-87\n",
      "199\t1.5419601854532917e-86\n",
      "200\t6.175550542745128e-86\n",
      "201\t2.4579305642786956e-85\n",
      "202\t9.722210499284553e-85\n",
      "203\t3.8218344721342614e-84\n",
      "204\t1.4931382717101205e-83\n",
      "205\t5.7977466550380235e-83\n",
      "206\t2.2374798984230973e-82\n",
      "207\t8.582410818105117e-82\n",
      "208\t3.272044124406048e-81\n",
      "209\t1.239932510299714e-80\n",
      "210\t4.6704124554619314e-80\n",
      "211\t1.7486378387757366e-79\n",
      "212\t6.507902145258391e-79\n",
      "213\t2.4076182584322836e-78\n",
      "214\t8.854184903675982e-78\n",
      "215\t3.2369252717633565e-77\n",
      "216\t1.1763825640436527e-76\n",
      "217\t4.250156360413722e-76\n",
      "218\t1.5265469863331868e-75\n",
      "219\t5.45095773201516e-75\n",
      "220\t1.9350899948651613e-74\n",
      "221\t6.829729393642823e-74\n",
      "222\t2.396558197141155e-73\n",
      "223\t8.36108644562668e-73\n",
      "224\t2.9002518608294446e-72\n",
      "225\t1.0002646417771085e-71\n",
      "226\t3.430111050347177e-71\n",
      "227\t1.1695620938183839e-70\n",
      "228\t3.965225870706467e-70\n",
      "229\t1.3367486341419086e-69\n",
      "230\t4.4810138996712714e-69\n",
      "231\t1.4936712998910073e-68\n",
      "232\t4.951005300063335e-68\n",
      "233\t1.6319193435413685e-67\n",
      "234\t5.3490689593902075e-67\n",
      "235\t1.7435688608029937e-66\n",
      "236\t5.651822790319475e-66\n",
      "237\t1.821937810887279e-65\n",
      "238\t5.8409182760827345e-65\n",
      "239\t1.8622509315368663e-64\n",
      "240\t5.90488732874207e-64\n",
      "241\t1.862122145164165e-63\n",
      "242\t5.84029218256088e-63\n",
      "243\t1.8217866149732648e-62\n",
      "244\t5.652018309570172e-62\n",
      "245\t1.7440513640931118e-61\n",
      "246\t5.35267796703712e-61\n",
      "247\t1.6339753794124589e-60\n",
      "248\t4.961223631836633e-60\n",
      "249\t1.4983293860019747e-59\n",
      "250\t4.500981475553087e-59\n",
      "251\t1.3449147835319462e-58\n",
      "252\t3.997385606608974e-58\n",
      "253\t1.1818357445616448e-57\n",
      "254\t3.4757137842021356e-57\n",
      "255\t1.0168166600071505e-56\n",
      "256\t2.9590953582232334e-56\n",
      "257\t8.566408352211237e-56\n",
      "258\t2.4669927929028873e-55\n",
      "259\t7.067600974266816e-55\n",
      "260\t2.014266277665556e-54\n",
      "261\t5.710946534381889e-54\n",
      "262\t1.6108356827874294e-53\n",
      "263\t4.520139672611184e-53\n",
      "264\t1.2618723252709978e-52\n",
      "265\t3.504671816601281e-52\n",
      "266\t9.683961598499538e-52\n",
      "267\t2.6621827016132585e-51\n",
      "268\t7.281268359257043e-51\n",
      "269\t1.9813711669058236e-50\n",
      "270\t5.364378974103129e-50\n",
      "271\t1.4450172144268237e-49\n",
      "272\t3.872858637192024e-49\n",
      "273\t1.0327623032519192e-48\n",
      "274\t2.740212388557014e-48\n",
      "275\t7.23416070578879e-48\n",
      "276\t1.9002777216291084e-47\n",
      "277\t4.966790868086318e-47\n",
      "278\t1.2917229487856141e-46\n",
      "279\t3.342738240230205e-46\n",
      "280\t8.607550968579771e-46\n",
      "281\t2.2054934866112823e-45\n",
      "282\t5.623226300972123e-45\n",
      "283\t1.4266701357250716e-44\n",
      "284\t3.601839744066596e-44\n",
      "285\t9.048832479827522e-44\n",
      "286\t2.2622081199549218e-43\n",
      "287\t5.627932395988182e-43\n",
      "288\t1.3933040966451577e-42\n",
      "289\t3.4326384664772486e-42\n",
      "290\t8.415882585058356e-42\n",
      "291\t2.0533596685171294e-41\n",
      "292\t4.98572604444662e-41\n",
      "293\t1.2047419929933298e-40\n",
      "294\t2.897117649815085e-40\n",
      "295\t6.933440883968938e-40\n",
      "296\t1.6513769672955962e-39\n",
      "297\t3.91437503359208e-39\n",
      "298\t9.234247143006153e-39\n",
      "299\t2.168040633573606e-38\n",
      "300\t5.065988280450237e-38\n",
      "301\t1.1781368094083576e-37\n",
      "302\t2.7268795687939536e-37\n",
      "303\t6.281722571014714e-37\n",
      "304\t1.4402502078940517e-36\n",
      "305\t3.286603753097283e-36\n",
      "306\t7.464671922887964e-36\n",
      "307\t1.6874535226321447e-35\n",
      "308\t3.796770425919704e-35\n",
      "309\t8.502799788798635e-35\n",
      "310\t1.8953015013098234e-34\n",
      "311\t4.205009761748796e-34\n",
      "312\t9.286063223861717e-34\n",
      "313\t2.0411538332317802e-33\n",
      "314\t4.465836571431662e-33\n",
      "315\t9.725599644461476e-33\n",
      "316\t2.1082391634334507e-32\n",
      "317\t4.5490081633729476e-32\n",
      "318\t9.770354011261976e-32\n",
      "319\t2.088834305857145e-31\n",
      "320\t4.445300507152312e-31\n",
      "321\t9.416835965314794e-31\n",
      "322\t1.985724105728066e-30\n",
      "323\t4.168176296232215e-30\n",
      "324\t8.70943010046632e-30\n",
      "325\t1.8115614608961536e-29\n",
      "326\t3.7509324727108815e-29\n",
      "327\t7.731279775568225e-29\n",
      "328\t1.5863266124863373e-28\n",
      "329\t3.2401564850780243e-28\n",
      "330\t6.588318186324195e-28\n",
      "331\t1.3335870649066483e-27\n",
      "332\t2.6872582723546388e-27\n",
      "333\t5.390656234037064e-27\n",
      "334\t1.0765172778754539e-26\n",
      "335\t2.1401806181026118e-26\n",
      "336\t4.235774139995562e-26\n",
      "337\t8.345857652695191e-26\n",
      "338\t1.6370720780290077e-25\n",
      "339\t3.196878217270079e-25\n",
      "340\t6.21510735769534e-25\n",
      "341\t1.2029240047149213e-24\n",
      "342\t2.317914968149103e-24\n",
      "343\t4.446612387879208e-24\n",
      "344\t8.492512612894484e-24\n",
      "345\t1.6148081953788652e-23\n",
      "346\t3.0569345895194156e-23\n",
      "347\t5.761484788313747e-23\n",
      "348\t1.0811061973485746e-22\n",
      "349\t2.0197170219775778e-22\n",
      "350\t3.756673660881418e-22\n",
      "351\t6.9568030757003e-22\n",
      "352\t1.2826605670831142e-21\n",
      "353\t2.3545723724365445e-21\n",
      "354\t4.3034133473580765e-21\n",
      "355\t7.831000063089595e-21\n",
      "356\t1.4188188316550683e-20\n",
      "357\t2.5594378923974048e-20\n",
      "358\t4.5969792313179504e-20\n",
      "359\t8.220781800851905e-20\n",
      "360\t1.463755870651092e-19\n",
      "361\t2.595024258216339e-19\n",
      "362\t4.580719616024954e-19\n",
      "363\t8.050961749381047e-19\n",
      "364\t1.4089183061403693e-18\n",
      "365\t2.4549918978258093e-18\n",
      "366\t4.259343866444959e-18\n",
      "367\t7.358103573089326e-18\n",
      "368\t1.2656737939592358e-17\n",
      "369\t2.1677664980532398e-17\n",
      "370\t3.6969207034404514e-17\n",
      "371\t6.277789873758627e-17\n",
      "372\t1.0614865136009017e-16\n",
      "373\t1.7871676422038325e-16\n",
      "374\t2.996133988398249e-16\n",
      "375\t5.001546337967992e-16\n",
      "376\t8.31374058837931e-16\n",
      "377\t1.3760674077309915e-15\n",
      "378\t2.267962949780177e-15\n",
      "379\t3.7220922289267146e-15\n",
      "380\t6.0826823004290205e-15\n",
      "381\t9.898328152928123e-15\n",
      "382\t1.603943750435304e-14\n",
      "383\t2.5880867826857215e-14\n",
      "384\t4.158462356555111e-14\n",
      "385\t6.653539770490561e-14\n",
      "386\t1.0600847043655823e-13\n",
      "387\t1.6818914947818144e-13\n",
      "388\t2.6572151708794855e-13\n",
      "389\t4.1805030451856744e-13\n",
      "390\t6.549454770795278e-13\n",
      "391\t1.0217819463386995e-12\n",
      "392\t1.587411238062085e-12\n",
      "393\t2.455842322497722e-12\n",
      "394\t3.783493121206901e-12\n",
      "395\t5.80454894038662e-12\n",
      "396\t8.86806088114029e-12\n",
      "397\t1.3491961642849712e-11\n",
      "398\t2.0441338870941714e-11\n",
      "399\t3.084131829651607e-11\n",
      "400\t4.6339080740549855e-11\n",
      "401\t6.933528290351105e-11\n",
      "402\t1.0331302104289098e-10\n",
      "403\t1.5330319251513436e-10\n",
      "404\t2.26539618642537e-10\n",
      "405\t3.3337682150827207e-10\n",
      "406\t4.885694797965239e-10\n",
      "407\t7.130473488926451e-10\n",
      "408\t1.0363653869928818e-09\n",
      "409\t1.5000692154037368e-09\n",
      "410\t2.1622948934235236e-09\n",
      "411\t3.1040242995627084e-09\n",
      "412\t4.437549302043881e-09\n",
      "413\t6.3178668029033126e-09\n",
      "414\t8.957941578038468e-09\n",
      "415\t1.2649045216219747e-08\n",
      "416\t1.7787719835306544e-08\n",
      "417\t2.4911339049938213e-08\n",
      "418\t3.4744762359112464e-08\n",
      "419\t4.826122122430677e-08\n",
      "420\t6.676135602704935e-08\n",
      "421\t9.197526483524844e-08\n",
      "422\t1.2619355056785312e-07\n",
      "423\t1.7243468611868832e-07\n",
      "424\t2.346575799303082e-07\n",
      "425\t3.1803003774094003e-07\n",
      "426\t4.292658960120487e-07\n",
      "427\t5.770459585733975e-07\n",
      "428\t7.725405006128099e-07\n",
      "429\t1.030054000817613e-06\n",
      "430\t1.3678158941095247e-06\n",
      "431\t1.8089444539249593e-06\n",
      "432\t2.382614338621468e-06\n",
      "433\t3.1254617652126447e-06\n",
      "434\t4.083264564231165e-06\n",
      "435\t5.312937341042149e-06\n",
      "436\t6.88488439837017e-06\n",
      "437\t8.885754692625688e-06\n",
      "438\t1.142164358892842e-05\n",
      "439\t1.462178518673793e-05\n",
      "440\t1.8642776113093096e-05\n",
      "441\t2.3673366492815762e-05\n",
      "442\t2.9939845858567555e-05\n",
      "443\t3.771204060741527e-05\n",
      "444\t4.7309924816032326e-05\n",
      "445\t5.9110827410548945e-05\n",
      "446\t7.355719554454264e-05\n",
      "447\t9.11648463797069e-05\n",
      "448\t0.00011253160724979722\n",
      "449\t0.00013834620757667123\n",
      "450\t0.00016939724527716355\n",
      "451\t0.00020658200643557985\n",
      "452\t0.0002509148706483123\n",
      "453\t0.00030353498700957465\n",
      "454\t0.0003657128587981393\n",
      "455\t0.0004388554305576971\n",
      "456\t0.0005245092316976946\n",
      "457\t0.0006243610985634053\n",
      "458\t0.0007402359749336824\n",
      "459\t0.0008740912819483815\n",
      "460\t0.0010280073555094026\n",
      "461\t0.0012041734749983738\n",
      "462\t0.0014048690541652218\n",
      "463\t0.0016324396352941052\n",
      "464\t0.0018892674227429305\n",
      "465\t0.0021777362120233615\n",
      "466\t0.0025001907155197903\n",
      "467\t0.0028588904541492397\n",
      "468\t0.00325595857278245\n",
      "469\t0.00369332614225826\n",
      "470\t0.004172672726675129\n",
      "471\t0.0046953642147387785\n",
      "472\t0.005262389130496052\n",
      "473\t0.005874294843344504\n",
      "474\t0.006531125279414726\n",
      "475\t0.007232361888361495\n",
      "476\t0.007976869729815662\n",
      "477\t0.008762850604663195\n",
      "478\t0.009587805159490793\n",
      "479\t0.010448505831422978\n",
      "480\t0.0113409823711908\n",
      "481\t0.012260521482376361\n",
      "482\t0.01320168184513274\n",
      "483\t0.014158325457084772\n",
      "484\t0.015123665829164839\n",
      "485\t0.016090333129578336\n",
      "486\t0.017050455888354\n",
      "487\t0.0179957583708629\n",
      "488\t0.018917672221837444\n",
      "489\t0.019807460485837026\n",
      "490\t0.020656351649521527\n",
      "491\t0.021455680939433834\n",
      "492\t0.022197035768633456\n",
      "493\t0.02287240196850115\n",
      "494\t0.023474307283429204\n",
      "495\t0.023995958556413993\n",
      "496\t0.024431369094742424\n",
      "497\t0.02477547288480803\n",
      "498\t0.025024222612575753\n",
      "499\t0.02517466884069764\n",
      "500\t0.025225018178380496\n",
      "501\t0.02517466884069764\n",
      "502\t0.025024222612575753\n",
      "503\t0.02477547288480803\n",
      "504\t0.024431369094742424\n",
      "505\t0.023995958556413993\n",
      "506\t0.023474307283429204\n",
      "507\t0.02287240196850115\n",
      "508\t0.022197035768633456\n",
      "509\t0.021455680939433834\n",
      "510\t0.020656351649521527\n",
      "511\t0.019807460485837026\n",
      "512\t0.018917672221837444\n",
      "513\t0.0179957583708629\n",
      "514\t0.017050455888354\n",
      "515\t0.016090333129578336\n",
      "516\t0.015123665829164839\n",
      "517\t0.014158325457084772\n",
      "518\t0.01320168184513274\n",
      "519\t0.012260521482376361\n",
      "520\t0.0113409823711908\n",
      "521\t0.010448505831422978\n",
      "522\t0.009587805159490793\n",
      "523\t0.008762850604663195\n",
      "524\t0.007976869729815662\n",
      "525\t0.007232361888361495\n",
      "526\t0.006531125279414726\n",
      "527\t0.005874294843344504\n",
      "528\t0.005262389130496052\n",
      "529\t0.0046953642147387785\n",
      "530\t0.004172672726675129\n",
      "531\t0.00369332614225826\n",
      "532\t0.00325595857278245\n",
      "533\t0.0028588904541492397\n",
      "534\t0.0025001907155197903\n",
      "535\t0.0021777362120233615\n",
      "536\t0.0018892674227429305\n",
      "537\t0.0016324396352941052\n",
      "538\t0.0014048690541652218\n",
      "539\t0.0012041734749983738\n",
      "540\t0.0010280073555094026\n",
      "541\t0.0008740912819483815\n",
      "542\t0.0007402359749336824\n",
      "543\t0.0006243610985634053\n",
      "544\t0.0005245092316976946\n",
      "545\t0.0004388554305576971\n",
      "546\t0.0003657128587981393\n",
      "547\t0.00030353498700957465\n",
      "548\t0.0002509148706483123\n",
      "549\t0.00020658200643557985\n",
      "550\t0.00016939724527716355\n",
      "551\t0.00013834620757667123\n",
      "552\t0.00011253160724979722\n",
      "553\t9.11648463797069e-05\n",
      "554\t7.355719554454264e-05\n",
      "555\t5.9110827410548945e-05\n",
      "556\t4.7309924816032326e-05\n",
      "557\t3.771204060741527e-05\n",
      "558\t2.9939845858567555e-05\n",
      "559\t2.3673366492815762e-05\n",
      "560\t1.8642776113093096e-05\n",
      "561\t1.462178518673793e-05\n",
      "562\t1.142164358892842e-05\n",
      "563\t8.885754692625688e-06\n",
      "564\t6.88488439837017e-06\n",
      "565\t5.312937341042149e-06\n",
      "566\t4.083264564231165e-06\n",
      "567\t3.1254617652126447e-06\n",
      "568\t2.382614338621468e-06\n",
      "569\t1.8089444539249593e-06\n",
      "570\t1.3678158941095247e-06\n",
      "571\t1.030054000817613e-06\n",
      "572\t7.725405006128099e-07\n",
      "573\t5.770459585733975e-07\n",
      "574\t4.292658960120487e-07\n",
      "575\t3.1803003774094003e-07\n",
      "576\t2.346575799303082e-07\n",
      "577\t1.7243468611868832e-07\n",
      "578\t1.2619355056785312e-07\n",
      "579\t9.197526483524844e-08\n",
      "580\t6.676135602704935e-08\n",
      "581\t4.826122122430677e-08\n",
      "582\t3.4744762359112464e-08\n",
      "583\t2.4911339049938213e-08\n",
      "584\t1.7787719835306544e-08\n",
      "585\t1.2649045216219747e-08\n",
      "586\t8.957941578038468e-09\n",
      "587\t6.3178668029033126e-09\n",
      "588\t4.437549302043881e-09\n",
      "589\t3.1040242995627084e-09\n",
      "590\t2.1622948934235236e-09\n",
      "591\t1.5000692154037368e-09\n",
      "592\t1.0363653869928818e-09\n",
      "593\t7.130473488926451e-10\n",
      "594\t4.885694797965239e-10\n",
      "595\t3.3337682150827207e-10\n",
      "596\t2.26539618642537e-10\n",
      "597\t1.5330319251513436e-10\n",
      "598\t1.0331302104289098e-10\n",
      "599\t6.933528290351105e-11\n",
      "600\t4.6339080740549855e-11\n",
      "601\t3.084131829651607e-11\n",
      "602\t2.0441338870941714e-11\n",
      "603\t1.3491961642849712e-11\n",
      "604\t8.86806088114029e-12\n",
      "605\t5.80454894038662e-12\n",
      "606\t3.783493121206901e-12\n",
      "607\t2.455842322497722e-12\n",
      "608\t1.587411238062085e-12\n",
      "609\t1.0217819463386995e-12\n",
      "610\t6.549454770795278e-13\n",
      "611\t4.1805030451856744e-13\n",
      "612\t2.6572151708794855e-13\n",
      "613\t1.6818914947818144e-13\n",
      "614\t1.0600847043655823e-13\n",
      "615\t6.653539770490561e-14\n",
      "616\t4.158462356555111e-14\n",
      "617\t2.5880867826857215e-14\n",
      "618\t1.603943750435304e-14\n",
      "619\t9.898328152928123e-15\n",
      "620\t6.0826823004290205e-15\n",
      "621\t3.7220922289267146e-15\n",
      "622\t2.267962949780177e-15\n",
      "623\t1.3760674077309915e-15\n",
      "624\t8.31374058837931e-16\n",
      "625\t5.001546337967992e-16\n",
      "626\t2.996133988398249e-16\n",
      "627\t1.7871676422038325e-16\n",
      "628\t1.0614865136009017e-16\n",
      "629\t6.277789873758627e-17\n",
      "630\t3.6969207034404514e-17\n",
      "631\t2.1677664980531782e-17\n",
      "632\t1.2656737939592358e-17\n",
      "633\t7.358103573089326e-18\n",
      "634\t4.259343866444959e-18\n",
      "635\t2.4549918978258093e-18\n",
      "636\t1.4089183061403693e-18\n",
      "637\t8.050961749381047e-19\n",
      "638\t4.580719616024954e-19\n",
      "639\t2.595024258216339e-19\n",
      "640\t1.463755870651092e-19\n",
      "641\t8.220781800851905e-20\n",
      "642\t4.5969792313179504e-20\n",
      "643\t2.5594378923974048e-20\n",
      "644\t1.4188188316550683e-20\n",
      "645\t7.831000063089595e-21\n",
      "646\t4.3034133473580765e-21\n",
      "647\t2.3545723724366114e-21\n",
      "648\t1.2826605670830779e-21\n",
      "649\t6.956803075700499e-22\n",
      "650\t3.7566736608813113e-22\n",
      "651\t2.0197170219776352e-22\n",
      "652\t1.081106197348544e-22\n",
      "653\t5.761484788313911e-23\n",
      "654\t3.0569345895193287e-23\n",
      "655\t1.614808195378911e-23\n",
      "656\t8.492512612894243e-24\n",
      "657\t4.446612387879334e-24\n",
      "658\t2.317914968149037e-24\n",
      "659\t1.2029240047149555e-24\n",
      "660\t6.215107357695164e-25\n",
      "661\t3.19687821727017e-25\n",
      "662\t1.6370720780290077e-25\n",
      "663\t8.345857652695191e-26\n",
      "664\t4.235774139995562e-26\n",
      "665\t2.1401806181026118e-26\n",
      "666\t1.0765172778754539e-26\n",
      "667\t5.390656234037064e-27\n",
      "668\t2.6872582723546388e-27\n",
      "669\t1.3335870649066483e-27\n",
      "670\t6.588318186324195e-28\n",
      "671\t3.2401564850780243e-28\n",
      "672\t1.5863266124863373e-28\n",
      "673\t7.731279775568225e-29\n",
      "674\t3.7509324727108815e-29\n",
      "675\t1.8115614608961536e-29\n",
      "676\t8.70943010046632e-30\n",
      "677\t4.168176296232096e-30\n",
      "678\t1.9857241057281222e-30\n",
      "679\t9.416835965314526e-31\n",
      "680\t4.445300507152438e-31\n",
      "681\t2.0888343058570855e-31\n",
      "682\t9.770354011262254e-32\n",
      "683\t4.5490081633728184e-32\n",
      "684\t2.1082391634335103e-32\n",
      "685\t9.725599644461199e-33\n",
      "686\t4.465836571431789e-33\n",
      "687\t2.0411538332317224e-33\n",
      "688\t9.28606322386198e-34\n",
      "689\t4.205009761748676e-34\n",
      "690\t1.8953015013098773e-34\n",
      "691\t8.502799788798394e-35\n",
      "692\t3.796770425919704e-35\n",
      "693\t1.6874535226321447e-35\n",
      "694\t7.464671922887964e-36\n",
      "695\t3.286603753097283e-36\n",
      "696\t1.4402502078940517e-36\n",
      "697\t6.281722571014714e-37\n",
      "698\t2.7268795687939536e-37\n",
      "699\t1.1781368094083576e-37\n",
      "700\t5.065988280450237e-38\n",
      "701\t2.168040633573606e-38\n",
      "702\t9.234247143006153e-39\n",
      "703\t3.91437503359208e-39\n",
      "704\t1.6513769672955962e-39\n",
      "705\t6.933440883968938e-40\n",
      "706\t2.897117649815085e-40\n",
      "707\t1.204741992993364e-40\n",
      "708\t4.985726044446478e-41\n",
      "709\t2.0533596685171878e-41\n",
      "710\t8.415882585058118e-42\n",
      "711\t3.432638466477346e-42\n",
      "712\t1.3933040966451182e-42\n",
      "713\t5.627932395988341e-43\n",
      "714\t2.2622081199548573e-43\n",
      "715\t9.04883247982778e-44\n",
      "716\t3.6018397440664933e-44\n",
      "717\t1.4266701357251122e-44\n",
      "718\t5.623226300971963e-45\n",
      "719\t2.2054934866113448e-45\n",
      "720\t8.607550968579527e-46\n",
      "721\t3.3427382402303e-46\n",
      "722\t1.2917229487856141e-46\n",
      "723\t4.966790868086318e-47\n",
      "724\t1.9002777216291084e-47\n",
      "725\t7.23416070578879e-48\n",
      "726\t2.740212388557014e-48\n",
      "727\t1.0327623032519192e-48\n",
      "728\t3.872858637192024e-49\n",
      "729\t1.4450172144268237e-49\n",
      "730\t5.364378974103129e-50\n",
      "731\t1.9813711669058236e-50\n",
      "732\t7.281268359257043e-51\n",
      "733\t2.6621827016132585e-51\n",
      "734\t9.683961598499538e-52\n",
      "735\t3.504671816601281e-52\n",
      "736\t1.2618723252709978e-52\n",
      "737\t4.520139672611056e-53\n",
      "738\t1.6108356827874753e-53\n",
      "739\t5.710946534381727e-54\n",
      "740\t2.014266277665613e-54\n",
      "741\t7.067600974266617e-55\n",
      "742\t2.4669927929029576e-55\n",
      "743\t8.566408352210992e-56\n",
      "744\t2.9590953582233176e-56\n",
      "745\t1.0168166600071215e-56\n",
      "746\t3.4757137842022346e-57\n",
      "747\t1.1818357445616111e-57\n",
      "748\t3.9973856066090875e-58\n",
      "749\t1.344914783531908e-58\n",
      "750\t4.500981475553215e-59\n",
      "751\t1.4983293860019323e-59\n",
      "752\t4.961223631836633e-60\n",
      "753\t1.6339753794124589e-60\n",
      "754\t5.35267796703712e-61\n",
      "755\t1.7440513640931118e-61\n",
      "756\t5.652018309570172e-62\n",
      "757\t1.8217866149732648e-62\n",
      "758\t5.84029218256088e-63\n",
      "759\t1.862122145164165e-63\n",
      "760\t5.90488732874207e-64\n",
      "761\t1.8622509315368663e-64\n",
      "762\t5.8409182760827345e-65\n",
      "763\t1.821937810887279e-65\n",
      "764\t5.651822790319475e-66\n",
      "765\t1.7435688608029937e-66\n",
      "766\t5.3490689593902075e-67\n",
      "767\t1.631919343541415e-67\n",
      "768\t4.951005300063194e-68\n",
      "769\t1.4936712998910498e-68\n",
      "770\t4.4810138996711437e-69\n",
      "771\t1.3367486341419467e-69\n",
      "772\t3.965225870706354e-70\n",
      "773\t1.1695620938184172e-70\n",
      "774\t3.430111050347079e-71\n",
      "775\t1.000264641777137e-71\n",
      "776\t2.900251860829362e-72\n",
      "777\t8.361086445626917e-73\n",
      "778\t2.3965581971410868e-73\n",
      "779\t6.829729393643017e-74\n",
      "780\t1.9350899948651064e-74\n",
      "781\t5.450957732015314e-75\n",
      "782\t1.5265469863331868e-75\n",
      "783\t4.250156360413722e-76\n",
      "784\t1.1763825640436527e-76\n",
      "785\t3.2369252717633565e-77\n",
      "786\t8.854184903675982e-78\n",
      "787\t2.4076182584322836e-78\n",
      "788\t6.507902145258391e-79\n",
      "789\t1.7486378387757366e-79\n",
      "790\t4.6704124554619314e-80\n",
      "791\t1.239932510299714e-80\n",
      "792\t3.272044124406048e-81\n",
      "793\t8.582410818105117e-82\n",
      "794\t2.2374798984230973e-82\n",
      "795\t5.7977466550380235e-83\n",
      "796\t1.4931382717101205e-83\n",
      "797\t3.8218344721341526e-84\n",
      "798\t9.722210499284829e-85\n",
      "799\t2.4579305642786256e-85\n",
      "800\t6.1755505427453034e-86\n",
      "801\t1.541960185453248e-86\n",
      "802\t3.8260608092944014e-87\n",
      "803\t9.434122543464332e-88\n",
      "804\t2.3115947028121383e-88\n",
      "805\t5.628230580770803e-89\n",
      "806\t1.3616686888938731e-89\n",
      "807\t3.273404283091727e-90\n",
      "808\t7.818898844515936e-91\n",
      "809\t1.8556595527170716e-91\n",
      "810\t4.375691044057867e-92\n",
      "811\t1.0251310707405393e-92\n",
      "812\t2.386080940518339e-93\n",
      "813\t5.51762874314479e-94\n",
      "814\t1.2675633599103798e-94\n",
      "815\t2.892843987036608e-95\n",
      "816\t6.558531098058769e-96\n",
      "817\t1.4770743231857094e-96\n",
      "818\t3.3044572266883375e-97\n",
      "819\t7.343238281533027e-98\n",
      "820\t1.620885523119251e-98\n",
      "821\t3.553707602449426e-99\n",
      "822\t7.738609012641132e-100\n",
      "823\t1.673721025818528e-100\n",
      "824\t3.5952502617733777e-101\n",
      "825\t7.669867225113302e-102\n",
      "826\t1.6249718697267894e-102\n",
      "827\t3.4189250947122066e-103\n",
      "828\t7.143406296915858e-104\n",
      "829\t1.482106010942614e-104\n",
      "830\t3.0534955165149037e-105\n",
      "831\t6.246621393594093e-106\n",
      "832\t1.2688449705730912e-106\n",
      "833\t2.5590150667017927e-107\n",
      "834\t5.124166860186853e-108\n",
      "835\t1.0186966452583961e-108\n",
      "836\t2.0105854840627428e-109\n",
      "837\t3.9394984395008383e-110\n",
      "838\t7.662747561316532e-111\n",
      "839\t1.4795770023057562e-111\n",
      "840\t2.835855921086076e-112\n",
      "841\t5.3952074598575e-113\n",
      "842\t1.0188099597583116e-113\n",
      "843\t1.9095133290835325e-114\n",
      "844\t3.552056785147053e-115\n",
      "845\t6.557643295653808e-116\n",
      "846\t1.2014594690618387e-116\n",
      "847\t2.1844717619309415e-117\n",
      "848\t3.941322872349838e-118\n",
      "849\t7.056314211981571e-119\n",
      "850\t1.2535334658923432e-119\n",
      "851\t2.2095184475225795e-120\n",
      "852\t3.8640639516521104e-121\n",
      "853\t6.704354804735351e-122\n",
      "854\t1.1540282860619729e-122\n",
      "855\t1.9706214007605794e-123\n",
      "856\t3.3380853167077657e-124\n",
      "857\t5.608918151761245e-125\n",
      "858\t9.348196919601548e-126\n",
      "859\t1.5453363941599443e-126\n",
      "860\t2.533632925310158e-127\n",
      "861\t4.1197283338351995e-128\n",
      "862\t6.64318141999583e-129\n",
      "863\t1.0622932050510481e-129\n",
      "864\t1.684423253380083e-130\n",
      "865\t2.6483417625378945e-131\n",
      "866\t4.128477343450035e-132\n",
      "867\t6.380806966803246e-133\n",
      "868\t9.77704293300069e-134\n",
      "869\t1.485120445519921e-134\n",
      "870\t2.2362158432550125e-135\n",
      "871\t3.3376355869499697e-136\n",
      "872\t4.937557232987584e-137\n",
      "873\t7.239488268296378e-138\n",
      "874\t1.0519622540880649e-138\n",
      "875\t1.5148256458871195e-139\n",
      "876\t2.1615662755245913e-140\n",
      "877\t3.056262464825165e-141\n",
      "878\t4.2815522001558204e-142\n",
      "879\t5.9425411651673125e-143\n",
      "880\t8.17099410210667e-144\n",
      "881\t1.1129617392204209e-144\n",
      "882\t1.5016150449798852e-145\n",
      "883\t2.006688282079175e-146\n",
      "884\t2.655910961575953e-147\n",
      "885\t3.4811940287352815e-148\n",
      "886\t4.518479834131088e-149\n",
      "887\t5.80729088039343e-150\n",
      "888\t7.389908440145743e-151\n",
      "889\t9.310120869468689e-152\n",
      "890\t1.161149906192459e-152\n",
      "891\t1.433518402706739e-153\n",
      "892\t1.7517209181074295e-154\n",
      "893\t2.118542655716232e-155\n",
      "894\t2.535615930219836e-156\n",
      "895\t3.003075850317302e-157\n",
      "896\t3.5192295120898933e-158\n",
      "897\t4.080266100970546e-159\n",
      "898\t4.680037955463554e-160\n",
      "899\t5.309942952802027e-161\n",
      "900\t5.958935980367618e-162\n",
      "901\t6.613691432145614e-163\n",
      "902\t7.258929620647828e-164\n",
      "903\t7.877908115440199e-165\n",
      "904\t8.453065123870979e-166\n",
      "905\t8.966787313714899e-167\n",
      "906\t9.402260428286516e-168\n",
      "907\t9.744349286203819e-169\n",
      "908\t9.980445854806528e-170\n",
      "909\t1.0101221327204984e-170\n",
      "910\t1.0101221327210248e-171\n",
      "911\t9.979252683309768e-173\n",
      "912\t9.738525096633494e-174\n",
      "913\t9.386530213629113e-175\n",
      "914\t8.934662238360092e-176\n",
      "915\t8.397606038238342e-177\n",
      "916\t7.792538354260391e-178\n",
      "917\t7.138203072600704e-179\n",
      "918\t6.453930882635363e-180\n",
      "919\t5.758676086787967e-181\n",
      "920\t5.070138728589327e-182\n",
      "921\t4.404029297359562e-183\n",
      "922\t3.77351751075539e-184\n",
      "923\t3.188888037257375e-185\n",
      "924\t2.6574066977137204e-186\n",
      "925\t2.183382800283159e-187\n",
      "926\t1.7683985963432495e-188\n",
      "927\t1.411666624912171e-189\n",
      "928\t1.110470513131119e-190\n",
      "929\t8.606445311677846e-192\n",
      "930\t6.570512012138078e-193\n",
      "931\t4.940234595590159e-194\n",
      "932\t3.657469818625176e-195\n",
      "933\t2.6656800393006e-196\n",
      "934\t1.9122115913601338e-197\n",
      "935\t1.3497964174315378e-198\n",
      "936\t9.373586232155349e-200\n",
      "937\t6.4024495075534626e-201\n",
      "938\t4.30015265433003e-202\n",
      "939\t2.8392914224526464e-203\n",
      "940\t1.842518901805357e-204\n",
      "941\t1.1748260797903825e-205\n",
      "942\t7.358252516732383e-207\n",
      "943\t4.525754464167747e-208\n",
      "944\t2.7327119116219533e-209\n",
      "945\t1.6193848365180408e-210\n",
      "946\t9.415028119287134e-212\n",
      "947\t5.368653837826157e-213\n",
      "948\t3.001462588654405e-214\n",
      "949\t1.644637034878066e-215\n",
      "950\t8.829104081983372e-217\n",
      "951\t4.642010558353284e-218\n",
      "952\t2.3892701403284227e-219\n",
      "953\t1.2034099342680146e-220\n",
      "954\t5.928749152053135e-222\n",
      "955\t2.8557325758595582e-223\n",
      "956\t1.344225584870753e-224\n",
      "957\t6.180347516653937e-226\n",
      "958\t2.7740599500608837e-227\n",
      "959\t1.2149167664500524e-228\n",
      "960\t5.188707023377908e-230\n",
      "961\t2.1597115601998176e-231\n",
      "962\t8.75558740621319e-233\n",
      "963\t3.4549566088927274e-234\n",
      "964\t1.326072557354974e-235\n",
      "965\t4.947006431585211e-237\n",
      "966\t1.792393634631781e-238\n",
      "967\t6.302107919080122e-240\n",
      "968\t2.1484458815029322e-241\n",
      "969\t7.094970919310955e-243\n",
      "970\t2.2674649329717145e-244\n",
      "971\t7.00555592061954e-246\n",
      "972\t2.090134996892055e-247\n",
      "973\t6.014776969480499e-249\n",
      "974\t1.667340638354704e-250\n",
      "975\t4.446241702283881e-252\n",
      "976\t1.1388938786592774e-253\n",
      "977\t2.7976922300694073e-255\n",
      "978\t6.579439804871213e-257\n",
      "979\t1.4785257988488824e-258\n",
      "980\t3.168269568958367e-260\n",
      "981\t6.459265176273511e-262\n",
      "982\t1.2497559913345134e-263\n",
      "983\t2.2884646840329276e-265\n",
      "984\t3.9536483362325125e-267\n",
      "985\t6.422169886269788e-269\n",
      "986\t9.77003532393424e-271\n",
      "987\t1.3858206133234934e-272\n",
      "988\t1.8234481754254712e-274\n",
      "989\t2.2124750359081712e-276\n",
      "990\t2.4583055954488076e-278\n",
      "991\t2.480631276944899e-280\n",
      "992\t2.250572731097086e-282\n",
      "993\t1.813150236534654e-284\n",
      "994\t1.276866363757387e-286\n",
      "995\t7.69969666587513e-289\n",
      "996\t3.8653095712193346e-291\n",
      "997\t1.5507761569596102e-293\n",
      "998\t4.661651774421211e-296\n",
      "999\t9.332636185042109e-299\n",
      "1000\t9.332636185032827e-302\n",
      "mean = 500.0\n",
      "variance = 250.0\n"
     ]
    }
   ],
   "source": [
    "# list of pmf values \n",
    "dist = [binom.pmf(r, n, p) for r in r_values ] \n",
    "# printing the table \n",
    "print(\"r\\tp(r)\") \n",
    "for i in range(n + 1): \n",
    "    print(str(r_values[i]) + \"\\t\" + str(dist[i])) \n",
    "# printing mean and variance \n",
    "print(\"mean = \"+str(mean)) \n",
    "print(\"variance = \"+str(var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution has a mean equal to np and a variance of np(1-p). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code: Plotting the graph using matplotlib.pyplot.bar() function to plot vertical bars.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import binom \n",
    "import matplotlib.pyplot as plt \n",
    "# setting the values \n",
    "# of n and p \n",
    "n = 1000\n",
    "p = 0.5\n",
    "# defining list of r values \n",
    "r_values = list(range(n + 1)) \n",
    "# list of pmf values \n",
    "dist = [binom.pmf(r, n, p) for r in r_values ] \n",
    "# plotting the graph  \n",
    "plt.bar(r_values, dist) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500 489 515 506 492 522 492 487 481 492 492 481 496 483 506 493 509 519\n",
      " 485 497 505 527 514 487 496 502 481 507 481 480 479 527 504 517 505 513\n",
      " 500 501 483 496 500 530 505 491 489 524 499 486 456 508 526 512 490 515\n",
      " 520 519 523 457 491 521 488 493 484 491 491 511 519 481 485 530 493 487\n",
      " 510 515 500 486 542 510 498 496 497 457 506 531 526 527 516 500 494 506\n",
      " 488 502 519 504 504 509 507 506 494 491 507 512 488 516 493 508 514 522\n",
      " 468 460 488 467 511 486 517 494 499 509 482 505 488 479 507 500 476 497\n",
      " 540 516 471 497 499 505 517 505 484 514 481 494 482 491 521 518 509 488\n",
      " 502 504 501 502 513 517 498 516 496 484 492 486 482 492 510 465 491 509\n",
      " 505 496 550 465 487 490 491 509 504 508 510 513 485 479 514 508 530 503\n",
      " 524 533 509 519 510 495 491 514 518 491 479 493 487 508 494 518 533 480\n",
      " 523 494 505 487 522 511 510 513 499 501 481 511 497 522 540 495 499 505\n",
      " 506 509 511 497 493 489 516 523 496 490 496 507 490 507 493 512 504 514\n",
      " 468 506 509 473 511 491 509 499 511 514 522 497 542 506 504 493 484 520\n",
      " 467 473 468 500 499 519 488 479 501 500 472 491 498 506 503 495 500 532\n",
      " 474 519 471 511 509 520 520 478 483 531 493 505 470 497 485 499 512 482\n",
      " 524 481 502 520 505 496 516 509 513 487 498 509 499 484 488 493 528 501\n",
      " 514 488 483 485 526 516 508 487 488 508 490 510 490 506 500 499 475 502\n",
      " 506 519 502 474 521 496 466 505 505 508 492 512 505 517 499 497 487 484\n",
      " 484 497 503 483 489 519 504 489 471 495 494 482 475 496 483 514 501 494\n",
      " 483 511 508 482 495 517 496 489 482 507 482 511 489 501 498 493 539 471\n",
      " 484 490 496 510 467 501 503 480 510 513 505 517 516 504 501 521 516 485\n",
      " 506 495 487 482 496 486 508 509 523 515 485 514 500 504 483 511 474 511\n",
      " 504 517 517 505 523 507 512 496 486 521 506 502 462 492 507 469 475 502\n",
      " 495 494 475 484 513 499 512 511 491 501 499 507 487 508 492 496 505 472\n",
      " 506 492 510 519 509 472 523 497 495 502 490 488 503 480 496 491 523 489\n",
      " 479 471 522 520 514 519 473 526 502 482 490 523 513 465 519 472 506 507\n",
      " 514 501 485 466 476 491 496 518 493 535 518 476 506 527 514 516 491 498\n",
      " 498 483 506 470 491 510 465 504 485 500 511 508 496 526 509 486 508 516\n",
      " 527 507 483 508 504 478 506 499 506 521 493 520 521 499 497 496 502 489\n",
      " 517 484 504 493 493 500 514 511 499 524 534 525 477 500 491 528 533 491\n",
      " 492 502 486 506 521 474 501 485 508 512 533 506 506 502 473 520 481 497\n",
      " 481 489 490 528 520 492 496 494 507 504 507 522 514 462 508 490 514 477\n",
      " 492 517 517 512 526 525 500 493 495 497 494 504 476 519 494 498 492 511\n",
      " 495 493 513 508 502 522 524 499 518 528 483 487 503 507 498 486 506 496\n",
      " 501 537 515 492 502 456 490 536 496 512 521 515 484 480 475 495 499 505\n",
      " 499 525 507 492 502 488 498 503 479 498 501 518 497 516 490 493 521 496\n",
      " 485 490 483 486 518 508 475 478 497 514 522 484 512 477 488 492 520 502\n",
      " 519 507 487 503 516 512 509 494 492 480 495 504 514 517 506 443 510 496\n",
      " 507 496 504 508 491 482 528 506 509 492 511 484 490 497 515 508 494 507\n",
      " 492 457 502 507 498 511 472 519 490 498 490 508 511 492 491 521 490 520\n",
      " 500 515 505 558 486 516 479 471 482 508 499 492 513 491 507 490 482 479\n",
      " 530 510 498 488 506 475 479 512 481 496 492 496 512 496 511 509 509 493\n",
      " 495 497 478 494 504 493 492 486 498 479 481 500 508 507 487 475 515 489\n",
      " 483 503 510 497 506 479 491 495 483 506 508 489 488 486 501 502 488 512\n",
      " 486 508 492 466 520 491 529 493 543 490 480 509 477 499 515 513 494 496\n",
      " 495 514 470 518 495 545 507 497 509 487 514 497 513 504 519 487 484 508\n",
      " 481 507 497 494 492 513 507 499 519 492 504 479 494 486 504 502 464 499\n",
      " 499 493 507 510 503 490 496 464 488 496 472 482 485 503 515 482 479 485\n",
      " 488 501 512 514 499 531 501 526 489 500 487 500 484 522 522 511 520 516\n",
      " 487 494 488 530 505 496 469 523 513 537 506 507 477 499 506 506 501 515\n",
      " 490 494 482 495 496 474 492 506 508 516 492 490 489 507 507 514 479 495\n",
      " 505 505 504 504 522 463 469 497 515 502 513 502 480 527 505 513 494 472\n",
      " 520 458 494 510 467 492 490 510 492 489 514 522 486 497 495 487 497 490\n",
      " 489 515 487 515 476 496 513 486 476 512 487 488 501 485 466 486 499 511\n",
      " 481 480 488 483 496 508 501 506 515 496]\n"
     ]
    }
   ],
   "source": [
    "r = binom.rvs(n, p, size=1000)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When success and failure are equally likely, the binomial distribution is a normal distribution. Hence, changing the value of p to 0.5, we obtain this graph, which is identical to a normal distribution plot :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 11\n",
    "p = 0.8\n",
    "# defining list of r values \n",
    "r_values = list(range(n + 1)) \n",
    "# list of pmf values \n",
    "dist = [binom.pmf(r, n, p) for r in r_values ] \n",
    "# plotting the graph  \n",
    "plt.bar(r_values, dist) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "# check scikit-learn version\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('lr',LogisticRegression()),('svm',SVC())]\n",
    "ensemble = VotingClassifier(estimators=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# test classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=2)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will demonstrate hard voting and soft voting for this dataset.\n",
    "\n",
    "## Hard Voting Ensemble for Classification\n",
    "We can demonstrate hard voting with a k-nearest neighbor algorithm.\n",
    "\n",
    "We can fit five different versions of the KNN algorithm, each with a different number of neighbors used when making predictions. We will use 1, 3, 5, 7, and 9 neighbors (odd numbers in an attempt to avoid ties).\n",
    "\n",
    "Our expectation is that by combining the predicted class labels predicted by each different KNN model that the hard voting ensemble will achieve a better predictive performance than any standalone model used in the ensemble, on average.\n",
    "\n",
    "First, we can create a function named get_voting() that creates each KNN model and combines the models into a hard voting ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# get a voting ensemble of models\n",
    "def get_voting():\n",
    "\t# define the base models\n",
    "\tmodels = list()\n",
    "\tmodels.append(('knn1', KNeighborsClassifier(n_neighbors=1)))\n",
    "\tmodels.append(('knn3', KNeighborsClassifier(n_neighbors=3)))\n",
    "\tmodels.append(('knn5', KNeighborsClassifier(n_neighbors=5)))\n",
    "\tmodels.append(('knn7', KNeighborsClassifier(n_neighbors=7)))\n",
    "\tmodels.append(('knn9', KNeighborsClassifier(n_neighbors=9)))\n",
    "\t# define the voting ensemble\n",
    "\tensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "\treturn ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create a list of models to evaluate, including each standalone version of the KNN model configurations and the hard voting ensemble.\n",
    "\n",
    "This will help us directly compare each standalone configuration of the KNN model with the ensemble in terms of the distribution of classification accuracy scores. The get_models() function below creates the list of models for us to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['knn1'] = KNeighborsClassifier(n_neighbors=1)\n",
    "\tmodels['knn3'] = KNeighborsClassifier(n_neighbors=3)\n",
    "\tmodels['knn5'] = KNeighborsClassifier(n_neighbors=5)\n",
    "\tmodels['knn7'] = KNeighborsClassifier(n_neighbors=7)\n",
    "\tmodels['knn9'] = KNeighborsClassifier(n_neighbors=9)\n",
    "\tmodels['hard_voting'] = get_voting()\n",
    "\treturn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn1': KNeighborsClassifier(n_neighbors=1),\n",
       " 'knn3': KNeighborsClassifier(n_neighbors=3),\n",
       " 'knn5': KNeighborsClassifier(),\n",
       " 'knn7': KNeighborsClassifier(n_neighbors=7),\n",
       " 'knn9': KNeighborsClassifier(n_neighbors=9),\n",
       " 'hard_voting': VotingClassifier(estimators=[('knn1', KNeighborsClassifier(n_neighbors=1)),\n",
       "                              ('knn3', KNeighborsClassifier(n_neighbors=3)),\n",
       "                              ('knn5', KNeighborsClassifier()),\n",
       "                              ('knn7', KNeighborsClassifier(n_neighbors=7)),\n",
       "                              ('knn9', KNeighborsClassifier(n_neighbors=9))])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=2)    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "X,y = get_dataset()\n",
    "\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom \n",
    "def get_binomial_dataset():\n",
    "   \n",
    "    # setting the values \n",
    "    # of n and p \n",
    "    n = 2 # Number of trials\n",
    "    p = 0.7 # Probability of success\n",
    "\n",
    "    # defining the list of r values \n",
    "    r_values = list(range(n + 1)) \n",
    "\n",
    "    # list of pmf values \n",
    "    dist = [binom.pmf(r, n, p) for r in r_values ] \n",
    "    # plotting the graph  \n",
    "    plt.bar(r_values, dist) \n",
    "    plt.show()\n",
    "    return r_values,dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X,y = get_binomial_dataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0009765625, 0.00976562500000001, 0.04394531249999999, 0.11718750000000014, 0.20507812500000022, 0.24609375000000025, 0.20507812500000022, 0.11718750000000014, 0.04394531249999999, 0.00976562500000001, 0.0009765625]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each model will be evaluated using repeated k-fold cross-validation.\n",
    "\n",
    "The evaluate_model() function below takes a model instance and returns as a list of scores from three repeats of stratified 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then report the mean performance of each algorithm, and also create a box and whisker plot to compare the distribution of accuracy scores for each algorithm.\n",
    "\n",
    "Tying this together, the complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:knn1 Score: 0.880 Mean:0.873 Std:0.030\n",
      "Model:knn3 Score: 0.870 Mean:0.889 Std:0.038\n",
      "Model:knn5 Score: 0.840 Mean:0.895 Std:0.031\n",
      "Model:knn7 Score: 0.880 Mean:0.899 Std:0.035\n",
      "Model:knn9 Score: 0.860 Mean:0.900 Std:0.033\n",
      "Model:hard_voting Score: 0.880 Mean:0.902 Std:0.034\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare hard voting to standalone classifiers\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    " \n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "#X,y = get_binomial_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('Model:%s Score: %.3f Mean:%.3f Std:%.3f' % (name, scores[1], mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 1., 2., 7., 4., 0., 2., 0., 1., 1.]),\n",
       " array([-5.52022952, -4.21792091, -2.9156123 , -1.61330369, -0.31099508,\n",
       "         0.99131354,  2.29362215,  3.59593076,  4.89823937,  6.20054798,\n",
       "         7.50285659]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pyplot.hist(results)\n",
    "#pyplot.show()\n",
    "import numpy as np\n",
    "counts, bins = np.histogram(data)\n",
    "pyplot.hist(bins[:-1], bins, weights=counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example first reports the mean and standard deviation accuracy for each model.\n",
    "\n",
    "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
    "\n",
    "We can see the hard voting ensemble achieves a better classification accuracy of about 90.2% compared to all standalone versions of the model.\n",
    "\n",
    "A box-and-whisker plot is then created comparing the distribution accuracy scores for each model, allowing us to clearly see that hard voting ensemble performing better than all standalone models on average.\n",
    "\n",
    "\n",
    "If we choose a hard voting ensemble as our final model, we can fit and use it to make predictions on new data just like any other model.\n",
    "\n",
    "First, the hard voting ensemble is fit on all available data, then the predict() function can be called to make predictions on new data.\n",
    "\n",
    "The example below demonstrates this on our binary classification dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.88891819  2.64867662 -0.42728226 ... -5.52022952  0.0364453\n",
      "  -1.960039  ]\n",
      " [ 6.97517717  3.01467478  2.00089741 ... -0.83596798  4.47708461\n",
      "  -1.93954487]\n",
      " [ 4.75991699 -0.55221295  2.85151795 ...  5.51656237  1.01637356\n",
      "   1.99141629]\n",
      " ...\n",
      " [-3.40090052 -1.07897489  6.81679768 ... -2.32336045 -5.11813849\n",
      "  -0.37726175]\n",
      " [-0.71293638 -1.67674502  0.15460334 ...  1.90768572 -0.91455953\n",
      "  -3.1331576 ]\n",
      " [ 0.59748892  3.4254834   0.74847355 ...  0.73366379  0.92401359\n",
      "   0.95631051]] [1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1 1 1 0\n",
      " 0 1 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1\n",
      " 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1\n",
      " 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1\n",
      " 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 1\n",
      " 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 0 0\n",
      " 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 1 0 0 1 1\n",
      " 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1\n",
      " 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1 1 0 1 0\n",
      " 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1 1 1\n",
      " 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0\n",
      " 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 0 0 0\n",
      " 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 1 1\n",
      " 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0\n",
      " 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1\n",
      " 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0\n",
      " 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1\n",
      " 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0\n",
      " 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0\n",
      " 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 1 1\n",
      " 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1 0\n",
      " 0 1 0 0 0 1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 1 1 0 0 0 0 0 1 1 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 0 0 1 0\n",
      " 0 1 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1\n",
      " 1]\n",
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "# make a prediction with a hard voting ensemble\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=2)\n",
    "print(X,y)\n",
    "#X,y = get_binomial_dataset()\n",
    "# define the base models\n",
    "models = list()\n",
    "models.append(('knn1', KNeighborsClassifier(n_neighbors=1)))\n",
    "models.append(('knn3', KNeighborsClassifier(n_neighbors=3)))\n",
    "models.append(('knn5', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('knn7', KNeighborsClassifier(n_neighbors=7)))\n",
    "models.append(('knn9', KNeighborsClassifier(n_neighbors=9)))\n",
    "# define the hard voting ensemble\n",
    "ensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "# fit the model on all available data\n",
    "ensemble.fit(X, y)\n",
    "# make a prediction for one example\n",
    "data = [[5.88891819,2.64867662,-0.42728226,-1.24988856,-0.00822,-3.57895574,2.87938412,-1.55614691,-0.38168784,7.50285659,-1.16710354,-5.02492712,-0.46196105,-0.64539455,-1.71297469,0.25987852,-0.193401,-5.52022952,0.0364453,-1.960039]]\n",
    "yhat = ensemble.predict(data)\n",
    "print('Predicted Class: %d' % (yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1 1 1 0\n",
      " 0 1 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1\n",
      " 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1\n",
      " 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1\n",
      " 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 1\n",
      " 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 0 0\n",
      " 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 1 0 0 1 1\n",
      " 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1\n",
      " 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1 1 0 1 0\n",
      " 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1 1 1\n",
      " 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0\n",
      " 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 0 0 0\n",
      " 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 1 1\n",
      " 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0\n",
      " 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1\n",
      " 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0\n",
      " 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1\n",
      " 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0\n",
      " 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0\n",
      " 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 1 1\n",
      " 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1 0\n",
      " 0 1 0 0 0 1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 1 1 0 0 0 0 0 1 1 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 0 0 1 0\n",
      " 0 1 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1\n",
      " 1] [1]\n"
     ]
    }
   ],
   "source": [
    "print(y,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1000, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-dd1a6066a831>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzero_one_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0merror_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mzero_one_loss\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    911\u001b[0m     score = accuracy_score(y_true, y_pred,\n\u001b[0;32m    912\u001b[0m                            \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 913\u001b[1;33m                            sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \"\"\"\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 256\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 1]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "\n",
    "\n",
    "accuracy = zero_one_loss(y, yhat)\n",
    "error_rate = 1 - accuracy\n",
    "print(error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example fits the hard voting ensemble model on the entire dataset and is then used to make a prediction on a new row of data, as we might when using the model in an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data : (891, 12)\n",
      "Shape of testing data : (418, 11)\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The following code is for Gradient Boosting\n",
    "Created by - ANALYTICS VIDHYA\n",
    "'''\n",
    "\n",
    "# importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# read the train and test dataset\n",
    "train_data = pd.read_csv('train-data.csv')\n",
    "test_data = pd.read_csv('test-data.csv')\n",
    "\n",
    "# shape of the dataset\n",
    "print('Shape of training data :',train_data.shape)\n",
    "print('Shape of testing data :',test_data.shape)\n",
    "print(train_data.head())\n",
    "print(test_data.head())\n",
    "# Now, we need to predict the missing target variable in the test data\n",
    "# target variable - Survived\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Survived'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-63041aa301e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# seperate the independent and target variable on testing data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtest_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4167\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4168\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4169\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4170\u001b[0m         )\n\u001b[0;32m   4171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3882\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3883\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3884\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3885\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3886\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3916\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3917\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3918\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3919\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3920\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5276\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5277\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5278\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5279\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5280\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Survived'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# seperate the independent and target variable on training data\n",
    "train_x = train_data.drop(['Survived'],axis=1)\n",
    "train_y = train_data['Survived']\n",
    "\n",
    "# seperate the independent and target variable on testing data\n",
    "test_x = test_data.drop(['Survived'],axis=1)\n",
    "test_y = test_data['Survived']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Success: 36\n"
     ]
    }
   ],
   "source": [
    "# example of simulating a binomial process and counting success\n",
    "from numpy.random import binomial\n",
    "# define the parameters of the distribution\n",
    "p = 0.3\n",
    "k = 100\n",
    "# run a single simulation\n",
    "success = binomial(k, p)\n",
    "print('Total Success: %d' % success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Success: 8\n"
     ]
    }
   ],
   "source": [
    "# example of simulating a binomial process and counting success\n",
    "from numpy.random import binomial\n",
    "# define the parameters of the distribution\n",
    "p = 0.8\n",
    "k = 11\n",
    "# run a single simulation\n",
    "success = binomial(k, p)\n",
    "print('Total Success: %d' % success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean=30.000, Variance=21.000\n"
     ]
    }
   ],
   "source": [
    "# calculate moments of a binomial distribution\n",
    "from scipy.stats import binom\n",
    "# define the parameters of the distribution\n",
    "p = 0.3\n",
    "k = 100\n",
    "# calculate moments\n",
    "mean, var, _, _ = binom.stats(k, p, moments='mvsk')\n",
    "print('Mean=%.3f, Variance=%.3f' % (mean, var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean=8.800, Variance=1.760\n"
     ]
    }
   ],
   "source": [
    "# calculate moments of a binomial distribution\n",
    "from scipy.stats import binom\n",
    "# define the parameters of the distribution\n",
    "p = 0.8\n",
    "k = 11\n",
    "# calculate moments\n",
    "mean, var, _, _ = binom.stats(k, p, moments='mvsk')\n",
    "print('Mean=%.3f, Variance=%.3f' % (mean, var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P of 6 success: 3.876%\n",
      "P of 7 success: 11.073%\n",
      "P of 8 success: 22.146%\n",
      "P of 9 success: 29.528%\n",
      "P of 10 success: 23.622%\n",
      "P of 11 success: 8.590%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# example of using the pmf for the binomial distribution\n",
    "from scipy.stats import binom\n",
    "# define the parameters of the distribution\n",
    "p = 0.8\n",
    "k = 11\n",
    "# define the distribution\n",
    "dist = binom(k, p)\n",
    "# calculate the probability of n successes\n",
    "for n in range(6, 12, 1):\n",
    "    print('P of %d success: %.3f%%' % (n, dist.pmf(n)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P of 10 success: 0.000%\n",
      "P of 20 success: 1.646%\n",
      "P of 30 success: 54.912%\n",
      "P of 40 success: 98.750%\n",
      "P of 50 success: 99.999%\n",
      "P of 60 success: 100.000%\n",
      "P of 70 success: 100.000%\n",
      "P of 80 success: 100.000%\n",
      "P of 90 success: 100.000%\n",
      "P of 100 success: 100.000%\n"
     ]
    }
   ],
   "source": [
    "# example of using the cdf for the binomial distribution\n",
    "from scipy.stats import binom\n",
    "# define the parameters of the distribution\n",
    "p = 0.3\n",
    "k = 100\n",
    "# define the distribution\n",
    "dist = binom(k, p)\n",
    "# calculate the probability of <=n successes\n",
    "for n in range(10, 110, 10):\n",
    "    print('P of %d success: %.3f%%' % (n, dist.cdf(n)*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
