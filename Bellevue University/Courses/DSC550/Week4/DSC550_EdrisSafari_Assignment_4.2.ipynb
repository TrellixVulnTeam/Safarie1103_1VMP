{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this assignment, we wrangle the data from controvertial comments data set.\n",
    "#### We will perfomr initial cleanup of the data and create new columns to work with\n",
    "#### We will thenvectorize the comments using  CountVectorizer and TF-IDF models.\n",
    "#### we will then calculate the jaccard distance beween two samples of the data set to show similairy\n",
    "#### Using keywords deemed toward 'liberal', 'conservative', 'Positive1','Positive2', and 'negative', we will quantify them and show scatter plot and stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def jaccard(a, b):\n",
    "    c = a.intersection(b)\n",
    "    #print(\"this is intersection\", c)\n",
    "    \n",
    "    d=a.union(b)\n",
    "    #print(\"this is union\", d)\n",
    "    _a = collections.Counter(a)\n",
    "    _b = collections.Counter(b)\n",
    "    c = (_a - _b) + (_b - _a)\n",
    "    #print(\"c\", c)\n",
    "    n = sum(c.values())\n",
    "    #print(_a)\n",
    "    #print(_b)\n",
    "    #print(\"_a and _b\")\n",
    "    #print (\"n\", n)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file ='controversial-comments.jsonl'\n",
    "# possible orient value: split, records, index, columns, and values)\n",
    "# The following file is a subset of above file with the 1st 233537 lines.\n",
    "dataframe = pd.read_json(\"controversial-comments_small.jsonl\",orient=\"columns\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# take a 1000 record sample of data with no duplicate records\n",
    "df1 = dataframe.sample(n=1000, replace=True, random_state=10)\n",
    "df2 = dataframe.sample(n=1000, replace=True, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# convert to lower case\n",
    "def ToLower(string: str) -> str:\n",
    "    return string.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1['lower_txt'] = [ToLower(string) for string in df1['txt']]\n",
    "df2['lower_txt'] = [ToLower(string) for string in df2['txt']]\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "# Tokenize words\n",
    "df1['Tokenized'] = [sent_tokenize(string) for string in df1['lower_txt']]\n",
    "df2['Tokenized'] = [sent_tokenize(string) for string in df2['lower_txt']]\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1['Tokenized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "#remove everything that has numbers in it\n",
    "def removeInvalidWords(text): \n",
    "    return re.sub(r\"\\d+\", '',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1['CleanText'] = [removeInvalidWords(string) for string in df1['lower_txt']]\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df2['CleanText'] = [removeInvalidWords(string) for string in df2['lower_txt']]\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use CountVectorizer to create list of words and feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X1 = vectorizer.fit_transform(df1['CleanText'])\n",
    "list1 = vectorizer.get_feature_names()\n",
    "print(list1[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print( X1.toarray())\n",
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X2 = vectorizer.fit_transform(df2['CleanText'])\n",
    "list2 = vectorizer.get_feature_names()\n",
    "print(list2[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print( X2.toarray())\n",
    "X2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### jaccard distance show the two samples are 90%  similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "words1 = set(list1)\n",
    "words2 = set(list2)\n",
    "\n",
    "z = jaccard(words1, words2)\n",
    "print(\"this is percent similarity\", z*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use TfidVectorizer  to create list of words and feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TfidVectorizer Example\n",
    "#Provide a list of all words in the corpus\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = df1['CleanText']\n",
    "vectorizer = TfidfVectorizer()\n",
    "X1 = vectorizer.fit_transform(corpus)\n",
    "list1 = vectorizer.get_feature_names()[:30]\n",
    "print(list1)\n",
    "\n",
    "print(X1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TfidVectorizer Example\n",
    "#Provide a list of all words in the corpus\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = df2['CleanText']\n",
    "vectorizer = TfidfVectorizer()\n",
    "X2 = vectorizer.fit_transform(corpus)\n",
    "list2 = vectorizer.get_feature_names()[:30]\n",
    "print(list2)\n",
    "\n",
    "print(X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "words1 = set(list1)\n",
    "words2 = set(list2)\n",
    "\n",
    "z = jaccard(words1, words2)\n",
    "print(\"this is percent similarity\", z*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TfidVectorizer Vectorization yield 100% similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentiment analyis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Take a 10,000 sample\n",
    "df = dataframe.sample(n=10000, replace=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['lower_txt'] = [ToLower(string) for string in df['txt']]\n",
    "df['CleanText'] = [removeInvalidWords(string) for string in df['lower_txt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['Liberal'] = df.CleanText.str.count('hillary') +  df.CleanText.str.count('clinton') +  df.CleanText.str.count('liberal') +  df.CleanText.str.count('wellware')\n",
    "df['Conservative']= df.CleanText.str.count('wall') +  df.CleanText.str.count('trump') +  df.CleanText.str.count('activits') + df.CleanText.str.count('taxes') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[['Liberal','Conservative']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NumberofLiberalComments = df['Liberal'][df.Liberal != 0].size\n",
    "NumberofConservativeComments = df['Conservative'][df.Conservative != 0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(NumberofLiberalComments)\n",
    "print(NumberofConservativeComments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(range(0,df['Liberal'].size),df['Liberal'],c='blue')\n",
    "plt.scatter(range(0,df['Conservative'].size),df['Conservative'],c='red')\n",
    "plt.title('Scatter Plot')\n",
    "plt.xlabel('comment numbers')\n",
    "plt.ylabel('liberal/Conservative')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### positive/negatve sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['positive1'] = df.CleanText.str.count('good')\n",
    "df['positive2']= df.CleanText.str.count('special')\n",
    "df['negative'] = df.CleanText.str.count('bad')\n",
    "df['TotScore'] = df.positive1 + df.positive2 - df.negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(range(0,df['positive1'].size),df['positive1'],c='blue')\n",
    "plt.scatter(range(0,df['positive2'].size),df['positive2'],c='green')\n",
    "plt.scatter(range(0,df['negative'].size),df['positive2'],c='red')\n",
    "plt.title('Scatter Plot')\n",
    "plt.xlabel('comment numbers')\n",
    "plt.ylabel('Positive/Negative')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}