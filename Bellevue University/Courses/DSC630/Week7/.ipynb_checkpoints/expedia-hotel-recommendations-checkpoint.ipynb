{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction #\n",
    "This kernel is writtern for the [Expedia Hotel Recommendations](https://www.kaggle.com/c/expedia-hotel-recommendations) competetion. If you Like the notebook and think that it helped you, <font color=\"red\"><b> please upvote</b></font>.\n",
    "\n",
    "---\n",
    "## Table of Content\n",
    "1. Data Preprocessing\n",
    "2. Modeling and Evaluation\n",
    "3. Final Prediction & Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-971e0173ba2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# get expedia & test csv files as a DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "\n",
    "# get expedia & test csv files as a DataFrame\n",
    "train_df = pd.read_csv('data/train.csv', nrows=10000)\n",
    "test_df    = pd.read_csv('data/test.csv', nrows=10000)\n",
    "destination = pd.read_csv('data/destinations.csv', nrows=100000)\n",
    "\n",
    "train_df.info()\n",
    "print(\"----------------------------\")\n",
    "test_df.info()\n",
    "\n",
    "# preview the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "The first step is to clean and pre-process the data and perform exploratory analysis to get some interesting insights into the process of choosing a hotel.\n",
    "\n",
    "* Remove the users who did not booked the hotel\n",
    "* Identify the searches by each user belonging to a specific type of destination\n",
    "* orig_destination_distance contains Nan values\n",
    "* The check-in and check-out dates to find the duration of the stay for each of the entries in the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Plot \n",
    "bookings_df = train_df[train_df[\"is_booking\"] == 1]\n",
    "fig, (axis1,axis2) = plt.subplots(2,1,figsize=(15,10))\n",
    "# What are the most countries the customer travel from?\n",
    "sns.countplot('user_location_country',data=bookings_df.sort_values(by=['user_location_country']),ax=axis1,palette=\"Set3\")\n",
    "\n",
    "# What are the most countries the customer travel to?\n",
    "sns.countplot('hotel_country',data=bookings_df.sort_values(by=['hotel_country']),ax=axis2,palette=\"Set3\")\n",
    "\n",
    "# Combine both plots\n",
    "# fig, (axis1) = plt.subplots(1,1,figsize=(15,5))\n",
    "# sns.distplot(bookings_df[\"hotel_country\"], kde=False, rug=False, bins=25, ax=axis1)\n",
    "# sns.distplot(bookings_df[\"user_location_country\"], kde=False, rug=False, bins=25, ax=axis1)\n",
    "\n",
    "# Where do most of the customers from a country travel?\n",
    "user_country_id = 66\n",
    "fig, (axis1) = plt.subplots(1,1,figsize=(15,10))\n",
    "country_customers = train_df[train_df[\"user_location_country\"] == user_country_id]\n",
    "country_customers[\"hotel_country\"].value_counts().plot(kind='bar',colormap=\"Set3\",figsize=(15,5))\n",
    "\n",
    "# Plot frequency for each hotel_clusters\n",
    "train_df[\"hotel_cluster\"].value_counts().plot(kind='bar',colormap=\"Set3\",figsize=(15,5))\n",
    "\n",
    "# What are the most frequent hotel clusters booked by customers from a country?\n",
    "fig, (axis1) = plt.subplots(1,1,figsize=(15,10))\n",
    "customer_clusters = train_df[train_df[\"user_location_country\"] == user_country_id][\"hotel_cluster\"]\n",
    "customer_clusters.value_counts().plot(kind='bar',colormap=\"Set3\",figsize=(15,5))\n",
    "\n",
    "# What are the most frequent hotel clusters in a country?\n",
    "country_id = 50\n",
    "fig, (axis1) = plt.subplots(1,1,figsize=(15,10))\n",
    "country_clusters = train_df[train_df[\"hotel_country\"] == country_id][\"hotel_cluster\"]\n",
    "country_clusters.value_counts().plot(kind='bar',colormap=\"Set3\",figsize=(15,5))\n",
    "\n",
    "# Plot post_continent & hotel_continent\n",
    "fig, ((axis1,axis2),(axis3,axis4)) = plt.subplots(2,2,figsize=(15,10))\n",
    "\n",
    "# Plot frequency for each posa_continent\n",
    "sns.countplot('posa_continent', data=train_df,order=[0,1,2,3,4],palette=\"Set3\",ax=axis1)\n",
    "\n",
    "# Plot frequency for each posa_continent decomposed by hotel_continent\n",
    "sns.countplot('posa_continent', hue='hotel_continent',data=train_df,order=[0,1,2,3,4],palette=\"Set3\",ax=axis2)\n",
    "\n",
    "# Plot frequency for each hotel_continent\n",
    "sns.countplot('hotel_continent', data=train_df,order=[0,2,3,4,5,6],palette=\"Set3\",ax=axis3)\n",
    "\n",
    "# Plot frequency for each hotel_continent decomposed by posa_continent\n",
    "sns.countplot('hotel_continent', hue='posa_continent', data=train_df, order=[0,2,3,4,5,6],palette=\"Set3\",ax=axis4)\n",
    "\n",
    "# Plot frequency of is_mobile & is_package\n",
    "fig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,3))\n",
    "\n",
    "# What's the frequency of bookings through mobile?\n",
    "sns.countplot(x='is_mobile',data=bookings_df, order=[0,1], palette=\"Set3\", ax=axis1)\n",
    "\n",
    "# What's the frequency of bookings with package?\n",
    "sns.countplot(x='is_package',data=bookings_df, order=[0,1], palette=\"Set3\", ax=axis2)\n",
    "\n",
    "# What's the most impactful channel?\n",
    "fig, (axis1) = plt.subplots(1,1,figsize=(15,3))\n",
    "sns.countplot(x='channel', order=list(range(0,10)), data=train_df, palette=\"Set3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(15, 10)\n",
    "sns.heatmap(train_df.corr(),cmap='coolwarm',ax=ax,annot=True,linewidths=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "**Additional features from date columns**\n",
    "* stay_dur: number of duration of stay\n",
    "* no_of_days_bet_booking: number of days between the booking and\n",
    "* Cin_day: Check-in day\n",
    "* Cin_month: Check-in month\n",
    "* Cin_year: Check-out year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to convert date object into relevant attributes\n",
    "def convert_date_into_days(df):\n",
    "    df['srch_ci'] = pd.to_datetime(df['srch_ci'])\n",
    "    df['srch_co'] = pd.to_datetime(df['srch_co'])\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    \n",
    "    df['stay_dur'] = (df['srch_co'] - df['srch_ci']).astype('timedelta64[D]')\n",
    "    df['no_of_days_bet_booking'] = (df['srch_ci'] - df['date_time']).astype('timedelta64[D]')\n",
    "    \n",
    "    # For hotel check-in\n",
    "    # Month, Year, Day\n",
    "    df['Cin_day'] = df[\"srch_ci\"].apply(lambda x: x.day)\n",
    "    df['Cin_month'] = df[\"srch_ci\"].apply(lambda x: x.month)\n",
    "    df['Cin_year'] = df[\"srch_ci\"].apply(lambda x: x.year)\n",
    "    \n",
    "convert_date_into_days(train_df)\n",
    "convert_date_into_days(test_df)\n",
    "\n",
    "# Count the bookings in each month\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(13, 8)\n",
    "sns.countplot('Cin_month',data=train_df[train_df[\"is_booking\"] == 1],order=list(range(1,13)),ax=ax)\n",
    "\n",
    "# Count the bookings as per the day\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(13, 8)\n",
    "sns.countplot('Cin_day',data=train_df[train_df[\"is_booking\"] == 1],order=list(range(1,32)),ax=ax)\n",
    "\n",
    "# Count the bookings as per the stay_duration\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(13, 8)\n",
    "sns.countplot('stay_dur',data=train_df[train_df[\"is_booking\"] == 1],ax=ax)\n",
    "\n",
    "# drop unnecessary columns, these columns won't be useful in analysis and prediction\n",
    "test_user_id = test_df['user_id']\n",
    "columns = ['date_time', 'srch_ci','user_id','srch_destination_type_id','srch_destination_id', 'site_name', 'user_location_region', 'user_location_city', \n",
    "                              'user_id', 'srch_co', 'srch_adults_cnt', 'srch_children_cnt', 'srch_rm_cnt']\n",
    "train_df.drop(columns=columns,axis=1,inplace=True)\n",
    "test_df.drop(columns=columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the percentage of Nan in dataset\n",
    "total = train_df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train_df.isnull().sum()/train_df['hotel_cluster'].count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data\n",
    "\n",
    "# Fill nan with the day which has max occurence\n",
    "train_df['Cin_day'] = train_df['Cin_day'].fillna(26.0)\n",
    "train_df['Cin_month'] = train_df['Cin_month'].fillna(8.0)\n",
    "train_df['Cin_year'] = train_df['Cin_year'].fillna(2014.0)\n",
    "train_df['stay_dur'] = train_df['stay_dur'].fillna(1.0)\n",
    "train_df['no_of_days_bet_booking'] = train_df['no_of_days_bet_booking'].fillna(0.0)\n",
    "\n",
    "# Fill average values in place for nan, fill with mean\n",
    "train_df['orig_destination_distance'].fillna(train_df['orig_destination_distance'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction & Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple solution\n",
    "A very simple solution implemented with pandas to use the \"most popular local hotel\" as recommendation.\n",
    "\n",
    "**Step 1**\n",
    "\n",
    "Read in the train data using only the necessary columns. Specifying dtypes helps reduce memory requirements.\n",
    "The file is read in chunks of 1 million rows each. In each chunk we count the number of rows and number of bookings for every destination-hotel cluster combination.\n",
    "\n",
    "**Step 2**\n",
    "\n",
    "Next we aggregate again to compute the total number of bookings over all chunks.\n",
    "Compute the number of clicks by subtracting the number of bookings from total row counts.\n",
    "Compute the 'relevance' of a hotel cluster with a weighted sum of bookings and clicks.\n",
    "\n",
    "**Step 3**\n",
    "Read in the test data and merge most popular hotel clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "train = pd.read_csv('../input/train.csv',\n",
    "                    dtype={'is_booking':bool,'srch_destination_id':np.int32, 'hotel_cluster':np.int32},\n",
    "                    usecols=['srch_destination_id','is_booking','hotel_cluster'],\n",
    "                    chunksize=1000000)\n",
    "aggs = []\n",
    "print('-'*38)\n",
    "for chunk in train:\n",
    "    agg = chunk.groupby(['srch_destination_id',\n",
    "                         'hotel_cluster'])['is_booking'].agg(['sum','count'])\n",
    "    agg.reset_index(inplace=True)\n",
    "    aggs.append(agg)\n",
    "    print('.',end='')\n",
    "print('')\n",
    "aggs = pd.concat(aggs, axis=0)\n",
    "aggs.head()\n",
    "\n",
    "# Step 2\n",
    "CLICK_WEIGHT = 0.05\n",
    "agg = aggs.groupby(['srch_destination_id','hotel_cluster']).sum().reset_index()\n",
    "agg['count'] -= agg['sum']\n",
    "agg = agg.rename(columns={'sum':'bookings','count':'clicks'})\n",
    "agg['relevance'] = agg['bookings'] + CLICK_WEIGHT * agg['clicks']\n",
    "agg.head()\n",
    "\n",
    "# Define a function to get most popular hotels for a destination group.\n",
    "def most_popular(group, n_max=5):\n",
    "    relevance = group['relevance'].values\n",
    "    hotel_cluster = group['hotel_cluster'].values\n",
    "    most_popular = hotel_cluster[np.argsort(relevance)[::-1]][:n_max]\n",
    "    return np.array_str(most_popular)[1:-1] # remove square brackets\n",
    "\n",
    "# Get most popular hotel clusters for all destinations.\n",
    "most_pop = agg.groupby(['srch_destination_id']).apply(most_popular)\n",
    "most_pop = pd.DataFrame(most_pop).rename(columns={0:'hotel_cluster'})\n",
    "most_pop.head()\n",
    "\n",
    "# Step 3: Read in the test data and merge most popular hotel clusters.\n",
    "test = pd.read_csv('../input/test.csv',\n",
    "                    dtype={'srch_destination_id':np.int32},\n",
    "                    usecols=['srch_destination_id'],)\n",
    "test = test.merge(most_pop, how='left',left_on='srch_destination_id',right_index=True)\n",
    "test.head()\n",
    "\n",
    "# Check hotel_cluster column in test for null values\n",
    "test.hotel_cluster.isnull().sum()\n",
    "\n",
    "# Let's fill nas with hotel clusters that are most popular overall.\n",
    "most_pop_all = agg.groupby('hotel_cluster')['relevance'].sum().nlargest(5).index\n",
    "most_pop_all = np.array_str(most_pop_all)[1:-1]\n",
    "print(most_pop_all)\n",
    "\n",
    "test.hotel_cluster.fillna(most_pop_all,inplace=True)\n",
    "\n",
    "test.hotel_cluster.to_csv('submission.csv',header=True, index_label='id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
