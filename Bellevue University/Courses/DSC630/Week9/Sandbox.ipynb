{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binomial Distribution- Theory\n",
    "\n",
    "\n",
    "**Binomial distribution** is a probability distribution that summarises the likelihood that a variable will take one of two independent values under a given set of parameters. The distribution is obtained by performing a number of **Bernoulli** trials.\n",
    "\n",
    "A Bernoulli trial is assumed to meet each of these criteria :\n",
    "\n",
    "- There must be only 2 possible outcomes.\n",
    "- Each outcome has a fixed probability of occurring. A success has the probability of p, and a failure has the probability of 1 – p.\n",
    "- Each trial is completely independent of all others.\n",
    "\n",
    "The binomial random variable represents the number of successes(r) in n successive independent trials of a Bernoulli experiment.\n",
    "\n",
    "Probability of achieving r success and n-r failure is :\n",
    "\n",
    "$$p^r * (1-p)^{n-r}$$\n",
    "\n",
    "The number of ways we can achieve r successes is : \n",
    "\n",
    "$$\\frac{n!}{(n-r)!\\ *\\ r!}$$\n",
    "\n",
    "Hence, the probability mass function(pmf), which is the total probability of achieving r success and n-r failure is :\n",
    "\n",
    "$$\\frac{n!}{(n-r)!\\ *\\ r!}\\ *\\ p^r * (1-p)^{n-r}$$\n",
    "\n",
    "An example illustrating the distribution :\n",
    "Consider a random experiment of tossing a biased coin 6 times where the probability of getting a head is 0.6. If ‘getting a head’ is considered as ‘success’ then, the binomial distribution table will contain the probability of r successes for each possible value of r.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binomial Distribution in model ensemble validation\n",
    "\n",
    "The ensemble in entirety, makes an error in case (M+1)/2 or more models make an error $\\epsilon$ simultaneously. Here, M is number of independent models and is assumed to be an odd number. The probability that exactly k independet models make an error is:\n",
    "\n",
    "$${P(exactly\\ k\\ hypotheses\\ make\\ an\\ error)} = \\binom{M}{k}\\ \\varepsilon^k{(1-\\varepsilon)}^{(M-k)}$$\n",
    "\n",
    "and \n",
    "\n",
    "$$P(error) = \\sum_{k=(M+1)/2}^{M}{P(exactly\\ k\\ hypotheses\\ make\\ an\\ error)} = \\sum_{k=(M+1)/2}^{M}{\\binom{M}{k}\\ \\varepsilon^k{(1-\\varepsilon)}^{(M-k)}}$$\n",
    "\n",
    ", where\n",
    "\n",
    "$$\\binom{M}{k}\\ = \\frac{M!}{k!(M-k)!}$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes the probability that (M+1)/2 or more models make an error 'e'.\n",
    "def ComputeErrorProbability(M,e):\n",
    "\n",
    "    # k is the minimum number of models making error 'e'.\n",
    "    k = int((M+1)/2)\n",
    "    prob = 0\n",
    "    # total probability is the sum of probabilities for values of k, K+1,..M\n",
    "    # M+1 because the range function is inclusive on lower bound of k, and exclusive on upper bound M+1 \n",
    "    for i in range(k,M+1):\n",
    "        prob += (math.factorial(M)/(math.factorial(i)* math.factorial(M-i)))*pow(e,i)*(pow((1-e),M-i))\n",
    "        \n",
    "    \n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The ensemble contains 11 independent models, all of which have an error rate of 0.2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011654205440000008\n"
     ]
    }
   ],
   "source": [
    "print(ComputeErrorProbability(11,.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The ensemble contains 11 independent models, all of which have an error rate of 0.49.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47294772571497457\n"
     ]
    }
   ],
   "source": [
    "print(ComputeErrorProbability(11,.49))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3. The ensemble contains 21 independent models, all of which have an error rate of 0.49."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46304790101273546\n"
     ]
    }
   ],
   "source": [
    "print(ComputeErrorProbability(21,.49))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24650186752000006\n"
     ]
    }
   ],
   "source": [
    "print(ComputeErrorProbability(11,.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "for i in range(6,12):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/voting-ensembles-with-python/#:~:text=A%20voting%20ensemble%20(or%20a,model%20used%20in%20the%20ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom \n",
    "# setting the values \n",
    "# of n and p \n",
    "n = 11 # Number of trials\n",
    "p = 0.8 # Probability of success\n",
    "\n",
    "# defining the list of r values \n",
    "r_values = list(range(n+1)) \n",
    "\n",
    "print(r_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5999999999999996 1.44\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# obtaining the mean and variance  \n",
    "mean, var = binom.stats(n, p) \n",
    "print(mean,var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of pmf values \n",
    "dist = [binom.pmf(r, n, p) for r in r_values ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004096000000000002"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r\tp(r)\n",
      "0\t0.004096000000000002\n",
      "1\t0.03686400000000005\n",
      "2\t0.13824000000000003\n",
      "3\t0.2764800000000001\n",
      "4\t0.31104\n",
      "5\t0.18662400000000007\n",
      "6\t0.04665599999999999\n",
      "mean = 3.5999999999999996\n",
      "variance = 1.44\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# printing the table \n",
    "print(\"r\\tp(r)\") \n",
    "for i in r_values: \n",
    "    print(str(r_values[i]) + \"\\t\" + str(dist[i])) \n",
    "    #print(i)\n",
    "# printing mean and variance \n",
    "print(\"mean = \"+str(mean)) \n",
    "print(\"variance = \"+str(var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution has a mean equal to np and a variance of np(1-p). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code: Plotting the graph using matplotlib.pyplot.bar() function to plot vertical bars.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "pycharm": {
     "name": "#%%"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import binom \n",
    "import matplotlib.pyplot as plt \n",
    "# setting the values \n",
    "# of n and p \n",
    "n = 11\n",
    "p = 0.2\n",
    "# defining list of r values \n",
    "r_values = list(range(n + 1)) \n",
    "# list of pmf values \n",
    "dist = [binom.pmf(r, n, p) for r in r_values ] \n",
    "# plotting the graph  \n",
    "plt.bar(r_values, dist) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = binom.rvs(n, p, size=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When success and failure are equally likely, the binomial distribution is a normal distribution. Hence, changing the value of p to 0.5, we obtain this graph, which is identical to a normal distribution plot :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 11\n",
    "p = 0.8\n",
    "# defining list of r values \n",
    "r_values = list(range(n + 1)) \n",
    "# list of pmf values \n",
    "dist = [binom.pmf(r, n, p) for r in r_values ] \n",
    "# plotting the graph  \n",
    "plt.bar(r_values, dist) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "# check scikit-learn version\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('lr',LogisticRegression()),('svm',SVC())]\n",
    "ensemble = VotingClassifier(estimators=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# test classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=2)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will demonstrate hard voting and soft voting for this dataset.\n",
    "\n",
    "## Hard Voting Ensemble for Classification\n",
    "We can demonstrate hard voting with a k-nearest neighbor algorithm.\n",
    "\n",
    "We can fit five different versions of the KNN algorithm, each with a different number of neighbors used when making predictions. We will use 1, 3, 5, 7, and 9 neighbors (odd numbers in an attempt to avoid ties).\n",
    "\n",
    "Our expectation is that by combining the predicted class labels predicted by each different KNN model that the hard voting ensemble will achieve a better predictive performance than any standalone model used in the ensemble, on average.\n",
    "\n",
    "First, we can create a function named get_voting() that creates each KNN model and combines the models into a hard voting ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# get a voting ensemble of models\n",
    "def get_voting():\n",
    "\t# define the base models\n",
    "\tmodels = list()\n",
    "\tmodels.append(('knn1', KNeighborsClassifier(n_neighbors=1)))\n",
    "\tmodels.append(('knn3', KNeighborsClassifier(n_neighbors=3)))\n",
    "\tmodels.append(('knn5', KNeighborsClassifier(n_neighbors=5)))\n",
    "\tmodels.append(('knn7', KNeighborsClassifier(n_neighbors=7)))\n",
    "\tmodels.append(('knn9', KNeighborsClassifier(n_neighbors=9)))\n",
    "\t# define the voting ensemble\n",
    "\tensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "\treturn ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create a list of models to evaluate, including each standalone version of the KNN model configurations and the hard voting ensemble.\n",
    "\n",
    "This will help us directly compare each standalone configuration of the KNN model with the ensemble in terms of the distribution of classification accuracy scores. The get_models() function below creates the list of models for us to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['knn1'] = KNeighborsClassifier(n_neighbors=1)\n",
    "\tmodels['knn3'] = KNeighborsClassifier(n_neighbors=3)\n",
    "\tmodels['knn5'] = KNeighborsClassifier(n_neighbors=5)\n",
    "\tmodels['knn7'] = KNeighborsClassifier(n_neighbors=7)\n",
    "\tmodels['knn9'] = KNeighborsClassifier(n_neighbors=9)\n",
    "\tmodels['hard_voting'] = get_voting()\n",
    "\treturn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn1': KNeighborsClassifier(n_neighbors=1),\n",
       " 'knn3': KNeighborsClassifier(n_neighbors=3),\n",
       " 'knn5': KNeighborsClassifier(),\n",
       " 'knn7': KNeighborsClassifier(n_neighbors=7),\n",
       " 'knn9': KNeighborsClassifier(n_neighbors=9),\n",
       " 'hard_voting': VotingClassifier(estimators=[('knn1', KNeighborsClassifier(n_neighbors=1)),\n",
       "                              ('knn3', KNeighborsClassifier(n_neighbors=3)),\n",
       "                              ('knn5', KNeighborsClassifier()),\n",
       "                              ('knn7', KNeighborsClassifier(n_neighbors=7)),\n",
       "                              ('knn9', KNeighborsClassifier(n_neighbors=9))])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=2)    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "X,y = get_dataset()\n",
    "\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom \n",
    "def get_binomial_dataset():\n",
    "   \n",
    "    # setting the values \n",
    "    # of n and p \n",
    "    n = 2 # Number of trials\n",
    "    p = 0.7 # Probability of success\n",
    "\n",
    "    # defining the list of r values \n",
    "    r_values = list(range(n + 1)) \n",
    "\n",
    "    # list of pmf values \n",
    "    dist = [binom.pmf(r, n, p) for r in r_values ] \n",
    "    # plotting the graph  \n",
    "    plt.bar(r_values, dist) \n",
    "    plt.show()\n",
    "    return r_values,dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X,y = get_binomial_dataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0009765625, 0.00976562500000001, 0.04394531249999999, 0.11718750000000014, 0.20507812500000022, 0.24609375000000025, 0.20507812500000022, 0.11718750000000014, 0.04394531249999999, 0.00976562500000001, 0.0009765625]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each model will be evaluated using repeated k-fold cross-validation.\n",
    "\n",
    "The evaluate_model() function below takes a model instance and returns as a list of scores from three repeats of stratified 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then report the mean performance of each algorithm, and also create a box and whisker plot to compare the distribution of accuracy scores for each algorithm.\n",
    "\n",
    "Tying this together, the complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:knn1 Score: 0.880 Mean:0.873 Std:0.030\n",
      "Model:knn3 Score: 0.870 Mean:0.889 Std:0.038\n",
      "Model:knn5 Score: 0.840 Mean:0.895 Std:0.031\n",
      "Model:knn7 Score: 0.880 Mean:0.899 Std:0.035\n",
      "Model:knn9 Score: 0.860 Mean:0.900 Std:0.033\n",
      "Model:hard_voting Score: 0.880 Mean:0.902 Std:0.034\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare hard voting to standalone classifiers\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    " \n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "#X,y = get_binomial_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('Model:%s Score: %.3f Mean:%.3f Std:%.3f' % (name, scores[1], mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 1., 2., 7., 4., 0., 2., 0., 1., 1.]),\n",
       " array([-5.52022952, -4.21792091, -2.9156123 , -1.61330369, -0.31099508,\n",
       "         0.99131354,  2.29362215,  3.59593076,  4.89823937,  6.20054798,\n",
       "         7.50285659]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pyplot.hist(results)\n",
    "#pyplot.show()\n",
    "import numpy as np\n",
    "counts, bins = np.histogram(data)\n",
    "pyplot.hist(bins[:-1], bins, weights=counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example first reports the mean and standard deviation accuracy for each model.\n",
    "\n",
    "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
    "\n",
    "We can see the hard voting ensemble achieves a better classification accuracy of about 90.2% compared to all standalone versions of the model.\n",
    "\n",
    "A box-and-whisker plot is then created comparing the distribution accuracy scores for each model, allowing us to clearly see that hard voting ensemble performing better than all standalone models on average.\n",
    "\n",
    "\n",
    "If we choose a hard voting ensemble as our final model, we can fit and use it to make predictions on new data just like any other model.\n",
    "\n",
    "First, the hard voting ensemble is fit on all available data, then the predict() function can be called to make predictions on new data.\n",
    "\n",
    "The example below demonstrates this on our binary classification dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.88891819  2.64867662 -0.42728226 ... -5.52022952  0.0364453\n",
      "  -1.960039  ]\n",
      " [ 6.97517717  3.01467478  2.00089741 ... -0.83596798  4.47708461\n",
      "  -1.93954487]\n",
      " [ 4.75991699 -0.55221295  2.85151795 ...  5.51656237  1.01637356\n",
      "   1.99141629]\n",
      " ...\n",
      " [-3.40090052 -1.07897489  6.81679768 ... -2.32336045 -5.11813849\n",
      "  -0.37726175]\n",
      " [-0.71293638 -1.67674502  0.15460334 ...  1.90768572 -0.91455953\n",
      "  -3.1331576 ]\n",
      " [ 0.59748892  3.4254834   0.74847355 ...  0.73366379  0.92401359\n",
      "   0.95631051]] [1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1 1 1 0\n",
      " 0 1 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1\n",
      " 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1\n",
      " 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1\n",
      " 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 1\n",
      " 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 0 0\n",
      " 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 1 0 0 1 1\n",
      " 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1\n",
      " 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1 1 0 1 0\n",
      " 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1 1 1\n",
      " 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0\n",
      " 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 0 0 0\n",
      " 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 1 1\n",
      " 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0\n",
      " 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1\n",
      " 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0\n",
      " 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1\n",
      " 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0\n",
      " 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0\n",
      " 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 1 1\n",
      " 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1 0\n",
      " 0 1 0 0 0 1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 1 1 0 0 0 0 0 1 1 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 0 0 1 0\n",
      " 0 1 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1\n",
      " 1]\n",
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "# make a prediction with a hard voting ensemble\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=2)\n",
    "print(X,y)\n",
    "#X,y = get_binomial_dataset()\n",
    "# define the base models\n",
    "models = list()\n",
    "models.append(('knn1', KNeighborsClassifier(n_neighbors=1)))\n",
    "models.append(('knn3', KNeighborsClassifier(n_neighbors=3)))\n",
    "models.append(('knn5', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('knn7', KNeighborsClassifier(n_neighbors=7)))\n",
    "models.append(('knn9', KNeighborsClassifier(n_neighbors=9)))\n",
    "# define the hard voting ensemble\n",
    "ensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "# fit the model on all available data\n",
    "ensemble.fit(X, y)\n",
    "# make a prediction for one example\n",
    "data = [[5.88891819,2.64867662,-0.42728226,-1.24988856,-0.00822,-3.57895574,2.87938412,-1.55614691,-0.38168784,7.50285659,-1.16710354,-5.02492712,-0.46196105,-0.64539455,-1.71297469,0.25987852,-0.193401,-5.52022952,0.0364453,-1.960039]]\n",
    "yhat = ensemble.predict(data)\n",
    "print('Predicted Class: %d' % (yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1 1 1 0\n",
      " 0 1 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1\n",
      " 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1\n",
      " 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1\n",
      " 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 1\n",
      " 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 0 0\n",
      " 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 1 0 0 1 1\n",
      " 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1\n",
      " 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1 1 0 1 0\n",
      " 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1 1 1\n",
      " 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0\n",
      " 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 0 0 0\n",
      " 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 1 1\n",
      " 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0\n",
      " 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1\n",
      " 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0\n",
      " 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1\n",
      " 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0\n",
      " 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0\n",
      " 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 1 1\n",
      " 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1 0\n",
      " 0 1 0 0 0 1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 1 1 0 0 0 0 0 1 1 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 0 0 1 0\n",
      " 0 1 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1\n",
      " 1] [1]\n"
     ]
    }
   ],
   "source": [
    "print(y,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1000, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-dd1a6066a831>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzero_one_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0merror_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mzero_one_loss\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    911\u001b[0m     score = accuracy_score(y_true, y_pred,\n\u001b[0;32m    912\u001b[0m                            \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 913\u001b[1;33m                            sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \"\"\"\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 256\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 1]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "\n",
    "\n",
    "accuracy = zero_one_loss(y, yhat)\n",
    "error_rate = 1 - accuracy\n",
    "print(error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example fits the hard voting ensemble model on the entire dataset and is then used to make a prediction on a new row of data, as we might when using the model in an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data : (891, 12)\n",
      "Shape of testing data : (418, 11)\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The following code is for Gradient Boosting\n",
    "Created by - ANALYTICS VIDHYA\n",
    "'''\n",
    "\n",
    "# importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# read the train and test dataset\n",
    "train_data = pd.read_csv('train-data.csv')\n",
    "test_data = pd.read_csv('test-data.csv')\n",
    "\n",
    "# shape of the dataset\n",
    "print('Shape of training data :',train_data.shape)\n",
    "print('Shape of testing data :',test_data.shape)\n",
    "print(train_data.head())\n",
    "print(test_data.head())\n",
    "# Now, we need to predict the missing target variable in the test data\n",
    "# target variable - Survived\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Survived'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-63041aa301e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# seperate the independent and target variable on testing data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtest_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4167\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4168\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4169\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4170\u001b[0m         )\n\u001b[0;32m   4171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3882\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3883\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3884\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3885\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3886\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3916\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3917\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3918\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3919\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3920\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\safar\\documents\\github\\safarie1103\\bellevue university\\courses\\dsc630\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5276\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5277\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5278\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5279\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5280\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Survived'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# seperate the independent and target variable on training data\n",
    "train_x = train_data.drop(['Survived'],axis=1)\n",
    "train_y = train_data['Survived']\n",
    "\n",
    "# seperate the independent and target variable on testing data\n",
    "test_x = test_data.drop(['Survived'],axis=1)\n",
    "test_y = test_data['Survived']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Success: 34\n"
     ]
    }
   ],
   "source": [
    "# example of simulating a binomial process and counting success\n",
    "from numpy.random import binomial\n",
    "# define the parameters of the distribution\n",
    "p = 0.3\n",
    "k = 100\n",
    "# run a single simulation\n",
    "success = binomial(k, p)\n",
    "print('Total Success: %d' % success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Success: 10\n"
     ]
    }
   ],
   "source": [
    "# example of simulating a binomial process and counting success\n",
    "from numpy.random import binomial\n",
    "# define the parameters of the distribution\n",
    "p = 0.8\n",
    "k = 11\n",
    "# run a single simulation\n",
    "success = binomial(k, p)\n",
    "print('Total Success: %d' % success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean=30.000, Variance=21.000\n"
     ]
    }
   ],
   "source": [
    "# calculate moments of a binomial distribution\n",
    "from scipy.stats import binom\n",
    "# define the parameters of the distribution\n",
    "p = 0.3\n",
    "k = 100\n",
    "# calculate moments\n",
    "mean, var, _, _ = binom.stats(k, p, moments='mvsk')\n",
    "print('Mean=%.3f, Variance=%.3f' % (mean, var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean=8.800, Variance=1.760\n"
     ]
    }
   ],
   "source": [
    "# calculate moments of a binomial distribution\n",
    "from scipy.stats import binom\n",
    "# define the parameters of the distribution\n",
    "p = 0.8\n",
    "k = 11\n",
    "# calculate moments\n",
    "mean, var, _, _ = binom.stats(k, p, moments='mvsk')\n",
    "print('Mean=%.3f, Variance=%.3f' % (mean, var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P of 6 success: 3.876%\n",
      "P of 7 success: 11.073%\n",
      "P of 8 success: 22.146%\n",
      "P of 9 success: 29.528%\n",
      "P of 10 success: 23.622%\n",
      "P of 11 success: 8.590%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# example of using the pmf for the binomial distribution\n",
    "from scipy.stats import binom\n",
    "# define the parameters of the distribution\n",
    "p = 0.8\n",
    "k = 11\n",
    "# define the distribution\n",
    "dist = binom(k, p)\n",
    "# calculate the probability of n successes\n",
    "for n in range(6, 12, 1):\n",
    "    print('P of %d success: %.3f%%' % (n, dist.pmf(n)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P of 10 success: 0.000%\n",
      "P of 20 success: 1.646%\n",
      "P of 30 success: 54.912%\n",
      "P of 40 success: 98.750%\n",
      "P of 50 success: 99.999%\n",
      "P of 60 success: 100.000%\n",
      "P of 70 success: 100.000%\n",
      "P of 80 success: 100.000%\n",
      "P of 90 success: 100.000%\n",
      "P of 100 success: 100.000%\n"
     ]
    }
   ],
   "source": [
    "# example of using the cdf for the binomial distribution\n",
    "from scipy.stats import binom\n",
    "# define the parameters of the distribution\n",
    "p = 0.3\n",
    "k = 100\n",
    "# define the distribution\n",
    "dist = binom(k, p)\n",
    "# calculate the probability of <=n successes\n",
    "for n in range(10, 110, 10):\n",
    "    print('P of %d success: %.3f%%' % (n, dist.cdf(n)*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
