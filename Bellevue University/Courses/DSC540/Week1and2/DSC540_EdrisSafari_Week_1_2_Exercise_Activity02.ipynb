{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Activity 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 - Get multiline text and save it in a Python variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Article = \"\"\"For data to be useful and meaningful, it must be curated and refined. Data Wrangling with Python teaches you all the core ideas behind these processes\n",
    "and equips you with knowledge about the most popular tools and techniques in the domain.\n",
    "\n",
    "The book starts with the absolute basics of Python, focusing mainly on data structures, and then quickly jumps into the NumPy and pandas libraries \n",
    "as the fundamental tools for data wrangling. We emphasize why you should stay away from the traditional way of data cleaning, as done in other languages, \n",
    "and take advantage of the specialized pre-built routines in Python. Thereafter, you will learn how, using the same Python backend, you can extract and \n",
    "transform data from a diverse array of sources, such as the internet, large database vaults, or Excel financial tables. Then, you will also learn how to handle missing or incorrect data, and reformat it based on the requirements from the downstream analytics tool. You will learn about these concepts through real-world\n",
    "examples and datasets. By the end of this book, you will be confident enough to handle a myriad of sources to extract, clean, trnsform, and format your data efficiently.\n",
    "\n",
    "Data science and analytics are taking over the whole world and the job of a data scientist is routinely being called the coolest job of the 21st century. \n",
    "But for all the emphasis on data, it is the science that makes you – the practitioner – truly valuable. \n",
    "\n",
    "To practice high-quality science with data, you need to make sure it is properly sourced, cleaned, formatted, and pre-processed. \n",
    "This book teaches you the most essential basics of this invaluable component of the data science pipeline: data wrangling. In short, data wrangling is the process that ensures that the data is in a format that is clean, accurate, formatted, and ready to be used for data analysis. \n",
    "\n",
    "A prominent example of data wrangling with a large amount of data is the one conducted at the Supercomputer Center of University of California \n",
    "San Diego (UCSD). The problem in California is that wildfires are very common, mainly because of the dry weather and extreme heat, especially during the summers. Data\n",
    "scientists at the UCSD Supercomputer Center gather data to predict the nature and spread direction of the fire. The data that comes from \n",
    "diverse sources such as weather stations, sensors in the forest, fire stations, satellite imagery, and Twitter feeds might still be incomplete \n",
    "or missing. This data needs to be cleaned and formatted so that it can be used to predict future occurrences of wildfires.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For data to be useful and meaningful, it must be curated and refined. Data Wrangling with Python teaches you all the core ideas behind these processes\\nand equips you with knowledge about the most popular tools and techniques in the domain.\\n\\nThe book starts with the absolute basics of Python, focusing mainly on data structures, and then quickly jumps into the NumPy and pandas libraries \\nas the fundamental tools for data wrangling. We emphasize why you should stay away from the traditional way of data cleaning, as done in other languages, \\nand take advantage of the specialized pre-built routines in Python. Thereafter, you will learn how, using the same Python backend, you can extract and \\ntransform data from a diverse array of\\xa0sources, such as the internet, large database vaults, or Excel financial tables. Then, you will also learn how to handle missing or incorrect data, and reformat it based\\xa0on the requirements from the downstream analytics tool. You will learn about\\xa0these concepts through real-world\\nexamples and datasets. By the end of this book, you will be confident enough to handle a myriad of\\xa0sources to extract, clean, trnsform, and format your data efficiently.\\n\\nData science and analytics are taking over the whole world and the job of a data scientist is routinely being called the coolest job of the 21st century. \\nBut for all the emphasis on data, it is the science that makes you – the practitioner – truly valuable. \\n\\nTo practice high-quality science with data, you need to make sure it is properly sourced, cleaned, formatted, and pre-processed. \\nThis book teaches you the most essential basics of this invaluable component of the data science pipeline: data wrangling. In short, data wrangling is the process that ensures that the data is in a format that is clean, accurate, formatted, and ready to be used for data analysis. \\n\\nA prominent example of data wrangling with a large amount of data is the one conducted at the Supercomputer Center of University of California \\nSan Diego (UCSD). The problem in California is that wildfires are very common, mainly because of the dry weather and extreme heat, especially during the summers. Data\\nscientists at the UCSD Supercomputer Center gather data to predict the nature and spread direction of the fire. The data that comes from \\ndiverse sources such as weather stations, sensors in the forest, fire stations, satellite imagery, and Twitter feeds might still be incomplete \\nor missing. This data needs to be cleaned and formatted so that it can be used to predict future occurrences of wildfires.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For data to be useful and meaningful, it must be curated and refined. Data Wrangling with Python teaches you all the core ideas behind these processesand equips you with knowledge about the most popular tools and techniques in the domain.The book starts with the absolute basics of Python, focusing mainly on data structures, and then quickly jumps into the NumPy and pandas libraries as the fundamental tools for data wrangling. We emphasize why you should stay away from the traditional way of data cleaning, as done in other languages, and take advantage of the specialized pre-built routines in Python. Thereafter, you will learn how, using the same Python backend, you can extract and transform data from a diverse array of sources, such as the internet, large database vaults, or Excel financial tables. Then, you will also learn how to handle missing or incorrect data, and reformat it based on the requirements from the downstream analytics tool. You will learn about these concepts through real-worldexamples and datasets. By the end of this book, you will be confident enough to handle a myriad of sources to extract, clean, trnsform, and format your data efficiently.Data science and analytics are taking over the whole world and the job of a data scientist is routinely being called the coolest job of the 21st century. But for all the emphasis on data, it is the science that makes you – the practitioner – truly valuable. To practice high-quality science with data, you need to make sure it is properly sourced, cleaned, formatted, and pre-processed. This book teaches you the most essential basics of this invaluable component of the data science pipeline: data wrangling. In short, data wrangling is the process that ensures that the data is in a format that is clean, accurate, formatted, and ready to be used for data analysis. A prominent example of data wrangling with a large amount of data is the one conducted at the Supercomputer Center of University of California San Diego (UCSD). The problem in California is that wildfires are very common, mainly because of the dry weather and extreme heat, especially during the summers. Datascientists at the UCSD Supercomputer Center gather data to predict the nature and spread direction of the fire. The data that comes from diverse sources such as weather stations, sensors in the forest, fire stations, satellite imagery, and Twitter feeds might still be incomplete or missing. This data needs to be cleaned and formatted so that it can be used to predict future occurrences of wildfires.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 - Get rid of all new lines in it using string methods \n",
    "Article = Article.replace('\\n', \"\")\n",
    "Article = Article.replace('\\xa0', \" \")\n",
    "Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for data to be useful and meaningful it must be curated and refined data wrangling with python teaches you all the core ideas behind these processesand equips you with knowledge about the most popular tools and techniques in the domainthe book starts with the absolute basics of python focusing mainly on data structures and then quickly jumps into the numpy and pandas libraries as the fundamental tools for data wrangling we emphasize why you should stay away from the traditional way of data cleaning as done in other languages and take advantage of the specialized prebuilt routines in python thereafter you will learn how using the same python backend you can extract and transform data from a diverse array of sources such as the internet large database vaults or excel financial tables then you will also learn how to handle missing or incorrect data and reformat it based on the requirements from the downstream analytics tool you will learn about these concepts through realworldexamples and datasets by the end of this book you will be confident enough to handle a myriad of sources to extract clean trnsform and format your data efficientlydata science and analytics are taking over the whole world and the job of a data scientist is routinely being called the coolest job of the 21st century but for all the emphasis on data it is the science that makes you  the practitioner  truly valuable to practice highquality science with data you need to make sure it is properly sourced cleaned formatted and preprocessed this book teaches you the most essential basics of this invaluable component of the data science pipeline data wrangling in short data wrangling is the process that ensures that the data is in a format that is clean accurate formatted and ready to be used for data analysis a prominent example of data wrangling with a large amount of data is the one conducted at the supercomputer center of university of california san diego ucsd the problem in california is that wildfires are very common mainly because of the dry weather and extreme heat especially during the summers datascientists at the ucsd supercomputer center gather data to predict the nature and spread direction of the fire the data that comes from diverse sources such as weather stations sensors in the forest fire stations satellite imagery and twitter feeds might still be incomplete or missing this data needs to be cleaned and formatted so that it can be used to predict future occurrences of wildfires'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuations \n",
    "import unicodedata\n",
    "import sys\n",
    "\n",
    "# Create a dictionary of punctuation characters\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                            if unicodedata.category(chr(i)).startswith('P'))\n",
    "\n",
    "# For each string, remove any punctuation characters\n",
    "cleaned_article = Article.translate(punctuation)\n",
    "cleaned_article = cleaned_article.lower()\n",
    "cleaned_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['for',\n",
       " 'data',\n",
       " 'to',\n",
       " 'be',\n",
       " 'useful',\n",
       " 'and',\n",
       " 'meaningful',\n",
       " 'it',\n",
       " 'must',\n",
       " 'be',\n",
       " 'curated',\n",
       " 'and',\n",
       " 'refined',\n",
       " 'data',\n",
       " 'wrangling',\n",
       " 'with',\n",
       " 'python',\n",
       " 'teaches',\n",
       " 'you',\n",
       " 'all',\n",
       " 'the',\n",
       " 'core',\n",
       " 'ideas',\n",
       " 'behind',\n",
       " 'these',\n",
       " 'processesand',\n",
       " 'equips',\n",
       " 'you',\n",
       " 'with',\n",
       " 'knowledge',\n",
       " 'about',\n",
       " 'the',\n",
       " 'most',\n",
       " 'popular',\n",
       " 'tools',\n",
       " 'and',\n",
       " 'techniques',\n",
       " 'in',\n",
       " 'the',\n",
       " 'domainthe',\n",
       " 'book',\n",
       " 'starts',\n",
       " 'with',\n",
       " 'the',\n",
       " 'absolute',\n",
       " 'basics',\n",
       " 'of',\n",
       " 'python',\n",
       " 'focusing',\n",
       " 'mainly',\n",
       " 'on',\n",
       " 'data',\n",
       " 'structures',\n",
       " 'and',\n",
       " 'then',\n",
       " 'quickly',\n",
       " 'jumps',\n",
       " 'into',\n",
       " 'the',\n",
       " 'numpy',\n",
       " 'and',\n",
       " 'pandas',\n",
       " 'libraries',\n",
       " 'as',\n",
       " 'the',\n",
       " 'fundamental',\n",
       " 'tools',\n",
       " 'for',\n",
       " 'data',\n",
       " 'wrangling',\n",
       " 'we',\n",
       " 'emphasize',\n",
       " 'why',\n",
       " 'you',\n",
       " 'should',\n",
       " 'stay',\n",
       " 'away',\n",
       " 'from',\n",
       " 'the',\n",
       " 'traditional',\n",
       " 'way',\n",
       " 'of',\n",
       " 'data',\n",
       " 'cleaning',\n",
       " 'as',\n",
       " 'done',\n",
       " 'in',\n",
       " 'other',\n",
       " 'languages',\n",
       " 'and',\n",
       " 'take',\n",
       " 'advantage',\n",
       " 'of',\n",
       " 'the',\n",
       " 'specialized',\n",
       " 'prebuilt',\n",
       " 'routines',\n",
       " 'in',\n",
       " 'python',\n",
       " 'thereafter',\n",
       " 'you',\n",
       " 'will',\n",
       " 'learn',\n",
       " 'how',\n",
       " 'using',\n",
       " 'the',\n",
       " 'same',\n",
       " 'python',\n",
       " 'backend',\n",
       " 'you',\n",
       " 'can',\n",
       " 'extract',\n",
       " 'and',\n",
       " 'transform',\n",
       " 'data',\n",
       " 'from',\n",
       " 'a',\n",
       " 'diverse',\n",
       " 'array',\n",
       " 'of',\n",
       " 'sources',\n",
       " 'such',\n",
       " 'as',\n",
       " 'the',\n",
       " 'internet',\n",
       " 'large',\n",
       " 'database',\n",
       " 'vaults',\n",
       " 'or',\n",
       " 'excel',\n",
       " 'financial',\n",
       " 'tables',\n",
       " 'then',\n",
       " 'you',\n",
       " 'will',\n",
       " 'also',\n",
       " 'learn',\n",
       " 'how',\n",
       " 'to',\n",
       " 'handle',\n",
       " 'missing',\n",
       " 'or',\n",
       " 'incorrect',\n",
       " 'data',\n",
       " 'and',\n",
       " 'reformat',\n",
       " 'it',\n",
       " 'based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'requirements',\n",
       " 'from',\n",
       " 'the',\n",
       " 'downstream',\n",
       " 'analytics',\n",
       " 'tool',\n",
       " 'you',\n",
       " 'will',\n",
       " 'learn',\n",
       " 'about',\n",
       " 'these',\n",
       " 'concepts',\n",
       " 'through',\n",
       " 'realworldexamples',\n",
       " 'and',\n",
       " 'datasets',\n",
       " 'by',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'this',\n",
       " 'book',\n",
       " 'you',\n",
       " 'will',\n",
       " 'be',\n",
       " 'confident',\n",
       " 'enough',\n",
       " 'to',\n",
       " 'handle',\n",
       " 'a',\n",
       " 'myriad',\n",
       " 'of',\n",
       " 'sources',\n",
       " 'to',\n",
       " 'extract',\n",
       " 'clean',\n",
       " 'trnsform',\n",
       " 'and',\n",
       " 'format',\n",
       " 'your',\n",
       " 'data',\n",
       " 'efficientlydata',\n",
       " 'science',\n",
       " 'and',\n",
       " 'analytics',\n",
       " 'are',\n",
       " 'taking',\n",
       " 'over',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'world',\n",
       " 'and',\n",
       " 'the',\n",
       " 'job',\n",
       " 'of',\n",
       " 'a',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'is',\n",
       " 'routinely',\n",
       " 'being',\n",
       " 'called',\n",
       " 'the',\n",
       " 'coolest',\n",
       " 'job',\n",
       " 'of',\n",
       " 'the',\n",
       " '21st',\n",
       " 'century',\n",
       " 'but',\n",
       " 'for',\n",
       " 'all',\n",
       " 'the',\n",
       " 'emphasis',\n",
       " 'on',\n",
       " 'data',\n",
       " 'it',\n",
       " 'is',\n",
       " 'the',\n",
       " 'science',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'you',\n",
       " 'the',\n",
       " 'practitioner',\n",
       " 'truly',\n",
       " 'valuable',\n",
       " 'to',\n",
       " 'practice',\n",
       " 'highquality',\n",
       " 'science',\n",
       " 'with',\n",
       " 'data',\n",
       " 'you',\n",
       " 'need',\n",
       " 'to',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'it',\n",
       " 'is',\n",
       " 'properly',\n",
       " 'sourced',\n",
       " 'cleaned',\n",
       " 'formatted',\n",
       " 'and',\n",
       " 'preprocessed',\n",
       " 'this',\n",
       " 'book',\n",
       " 'teaches',\n",
       " 'you',\n",
       " 'the',\n",
       " 'most',\n",
       " 'essential',\n",
       " 'basics',\n",
       " 'of',\n",
       " 'this',\n",
       " 'invaluable',\n",
       " 'component',\n",
       " 'of',\n",
       " 'the',\n",
       " 'data',\n",
       " 'science',\n",
       " 'pipeline',\n",
       " 'data',\n",
       " 'wrangling',\n",
       " 'in',\n",
       " 'short',\n",
       " 'data',\n",
       " 'wrangling',\n",
       " 'is',\n",
       " 'the',\n",
       " 'process',\n",
       " 'that',\n",
       " 'ensures',\n",
       " 'that',\n",
       " 'the',\n",
       " 'data',\n",
       " 'is',\n",
       " 'in',\n",
       " 'a',\n",
       " 'format',\n",
       " 'that',\n",
       " 'is',\n",
       " 'clean',\n",
       " 'accurate',\n",
       " 'formatted',\n",
       " 'and',\n",
       " 'ready',\n",
       " 'to',\n",
       " 'be',\n",
       " 'used',\n",
       " 'for',\n",
       " 'data',\n",
       " 'analysis',\n",
       " 'a',\n",
       " 'prominent',\n",
       " 'example',\n",
       " 'of',\n",
       " 'data',\n",
       " 'wrangling',\n",
       " 'with',\n",
       " 'a',\n",
       " 'large',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'data',\n",
       " 'is',\n",
       " 'the',\n",
       " 'one',\n",
       " 'conducted',\n",
       " 'at',\n",
       " 'the',\n",
       " 'supercomputer',\n",
       " 'center',\n",
       " 'of',\n",
       " 'university',\n",
       " 'of',\n",
       " 'california',\n",
       " 'san',\n",
       " 'diego',\n",
       " 'ucsd',\n",
       " 'the',\n",
       " 'problem',\n",
       " 'in',\n",
       " 'california',\n",
       " 'is',\n",
       " 'that',\n",
       " 'wildfires',\n",
       " 'are',\n",
       " 'very',\n",
       " 'common',\n",
       " 'mainly',\n",
       " 'because',\n",
       " 'of',\n",
       " 'the',\n",
       " 'dry',\n",
       " 'weather',\n",
       " 'and',\n",
       " 'extreme',\n",
       " 'heat',\n",
       " 'especially',\n",
       " 'during',\n",
       " 'the',\n",
       " 'summers',\n",
       " 'datascientists',\n",
       " 'at',\n",
       " 'the',\n",
       " 'ucsd',\n",
       " 'supercomputer',\n",
       " 'center',\n",
       " 'gather',\n",
       " 'data',\n",
       " 'to',\n",
       " 'predict',\n",
       " 'the',\n",
       " 'nature',\n",
       " 'and',\n",
       " 'spread',\n",
       " 'direction',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fire',\n",
       " 'the',\n",
       " 'data',\n",
       " 'that',\n",
       " 'comes',\n",
       " 'from',\n",
       " 'diverse',\n",
       " 'sources',\n",
       " 'such',\n",
       " 'as',\n",
       " 'weather',\n",
       " 'stations',\n",
       " 'sensors',\n",
       " 'in',\n",
       " 'the',\n",
       " 'forest',\n",
       " 'fire',\n",
       " 'stations',\n",
       " 'satellite',\n",
       " 'imagery',\n",
       " 'and',\n",
       " 'twitter',\n",
       " 'feeds',\n",
       " 'might',\n",
       " 'still',\n",
       " 'be',\n",
       " 'incomplete',\n",
       " 'or',\n",
       " 'missing',\n",
       " 'this',\n",
       " 'data',\n",
       " 'needs',\n",
       " 'to',\n",
       " 'be',\n",
       " 'cleaned',\n",
       " 'and',\n",
       " 'formatted',\n",
       " 'so',\n",
       " 'that',\n",
       " 'it',\n",
       " 'can',\n",
       " 'be',\n",
       " 'used',\n",
       " 'to',\n",
       " 'predict',\n",
       " 'future',\n",
       " 'occurrences',\n",
       " 'of',\n",
       " 'wildfires']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize will create a list of all the words in the text\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenize words\n",
    "list_of_words = word_tokenize(cleaned_article)\n",
    "list_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create a histograms of words with the number of times they were repeated in the text\n",
    "hist = {}\n",
    "for x in list_of_words:\n",
    "    hist[x] = hist.get(x, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'for': 4,\n",
       " 'data': 21,\n",
       " 'to': 10,\n",
       " 'be': 7,\n",
       " 'useful': 1,\n",
       " 'and': 18,\n",
       " 'meaningful': 1,\n",
       " 'it': 5,\n",
       " 'must': 1,\n",
       " 'curated': 1,\n",
       " 'refined': 1,\n",
       " 'wrangling': 5,\n",
       " 'with': 5,\n",
       " 'python': 4,\n",
       " 'teaches': 2,\n",
       " 'you': 11,\n",
       " 'all': 2,\n",
       " 'the': 34,\n",
       " 'core': 1,\n",
       " 'ideas': 1,\n",
       " 'behind': 1,\n",
       " 'these': 2,\n",
       " 'processesand': 1,\n",
       " 'equips': 1,\n",
       " 'knowledge': 1,\n",
       " 'about': 2,\n",
       " 'most': 2,\n",
       " 'popular': 1,\n",
       " 'tools': 2,\n",
       " 'techniques': 1,\n",
       " 'in': 7,\n",
       " 'domainthe': 1,\n",
       " 'book': 3,\n",
       " 'starts': 1,\n",
       " 'absolute': 1,\n",
       " 'basics': 2,\n",
       " 'of': 17,\n",
       " 'focusing': 1,\n",
       " 'mainly': 2,\n",
       " 'on': 3,\n",
       " 'structures': 1,\n",
       " 'then': 2,\n",
       " 'quickly': 1,\n",
       " 'jumps': 1,\n",
       " 'into': 1,\n",
       " 'numpy': 1,\n",
       " 'pandas': 1,\n",
       " 'libraries': 1,\n",
       " 'as': 4,\n",
       " 'fundamental': 1,\n",
       " 'we': 1,\n",
       " 'emphasize': 1,\n",
       " 'why': 1,\n",
       " 'should': 1,\n",
       " 'stay': 1,\n",
       " 'away': 1,\n",
       " 'from': 4,\n",
       " 'traditional': 1,\n",
       " 'way': 1,\n",
       " 'cleaning': 1,\n",
       " 'done': 1,\n",
       " 'other': 1,\n",
       " 'languages': 1,\n",
       " 'take': 1,\n",
       " 'advantage': 1,\n",
       " 'specialized': 1,\n",
       " 'prebuilt': 1,\n",
       " 'routines': 1,\n",
       " 'thereafter': 1,\n",
       " 'will': 4,\n",
       " 'learn': 3,\n",
       " 'how': 2,\n",
       " 'using': 1,\n",
       " 'same': 1,\n",
       " 'backend': 1,\n",
       " 'can': 2,\n",
       " 'extract': 2,\n",
       " 'transform': 1,\n",
       " 'a': 6,\n",
       " 'diverse': 2,\n",
       " 'array': 1,\n",
       " 'sources': 3,\n",
       " 'such': 2,\n",
       " 'internet': 1,\n",
       " 'large': 2,\n",
       " 'database': 1,\n",
       " 'vaults': 1,\n",
       " 'or': 3,\n",
       " 'excel': 1,\n",
       " 'financial': 1,\n",
       " 'tables': 1,\n",
       " 'also': 1,\n",
       " 'handle': 2,\n",
       " 'missing': 2,\n",
       " 'incorrect': 1,\n",
       " 'reformat': 1,\n",
       " 'based': 1,\n",
       " 'requirements': 1,\n",
       " 'downstream': 1,\n",
       " 'analytics': 2,\n",
       " 'tool': 1,\n",
       " 'concepts': 1,\n",
       " 'through': 1,\n",
       " 'realworldexamples': 1,\n",
       " 'datasets': 1,\n",
       " 'by': 1,\n",
       " 'end': 1,\n",
       " 'this': 4,\n",
       " 'confident': 1,\n",
       " 'enough': 1,\n",
       " 'myriad': 1,\n",
       " 'clean': 2,\n",
       " 'trnsform': 1,\n",
       " 'format': 2,\n",
       " 'your': 1,\n",
       " 'efficientlydata': 1,\n",
       " 'science': 4,\n",
       " 'are': 2,\n",
       " 'taking': 1,\n",
       " 'over': 1,\n",
       " 'whole': 1,\n",
       " 'world': 1,\n",
       " 'job': 2,\n",
       " 'scientist': 1,\n",
       " 'is': 8,\n",
       " 'routinely': 1,\n",
       " 'being': 1,\n",
       " 'called': 1,\n",
       " 'coolest': 1,\n",
       " '21st': 1,\n",
       " 'century': 1,\n",
       " 'but': 1,\n",
       " 'emphasis': 1,\n",
       " 'that': 7,\n",
       " 'makes': 1,\n",
       " 'practitioner': 1,\n",
       " 'truly': 1,\n",
       " 'valuable': 1,\n",
       " 'practice': 1,\n",
       " 'highquality': 1,\n",
       " 'need': 1,\n",
       " 'make': 1,\n",
       " 'sure': 1,\n",
       " 'properly': 1,\n",
       " 'sourced': 1,\n",
       " 'cleaned': 2,\n",
       " 'formatted': 3,\n",
       " 'preprocessed': 1,\n",
       " 'essential': 1,\n",
       " 'invaluable': 1,\n",
       " 'component': 1,\n",
       " 'pipeline': 1,\n",
       " 'short': 1,\n",
       " 'process': 1,\n",
       " 'ensures': 1,\n",
       " 'accurate': 1,\n",
       " 'ready': 1,\n",
       " 'used': 2,\n",
       " 'analysis': 1,\n",
       " 'prominent': 1,\n",
       " 'example': 1,\n",
       " 'amount': 1,\n",
       " 'one': 1,\n",
       " 'conducted': 1,\n",
       " 'at': 2,\n",
       " 'supercomputer': 2,\n",
       " 'center': 2,\n",
       " 'university': 1,\n",
       " 'california': 2,\n",
       " 'san': 1,\n",
       " 'diego': 1,\n",
       " 'ucsd': 2,\n",
       " 'problem': 1,\n",
       " 'wildfires': 2,\n",
       " 'very': 1,\n",
       " 'common': 1,\n",
       " 'because': 1,\n",
       " 'dry': 1,\n",
       " 'weather': 2,\n",
       " 'extreme': 1,\n",
       " 'heat': 1,\n",
       " 'especially': 1,\n",
       " 'during': 1,\n",
       " 'summers': 1,\n",
       " 'datascientists': 1,\n",
       " 'gather': 1,\n",
       " 'predict': 2,\n",
       " 'nature': 1,\n",
       " 'spread': 1,\n",
       " 'direction': 1,\n",
       " 'fire': 2,\n",
       " 'comes': 1,\n",
       " 'stations': 2,\n",
       " 'sensors': 1,\n",
       " 'forest': 1,\n",
       " 'satellite': 1,\n",
       " 'imagery': 1,\n",
       " 'twitter': 1,\n",
       " 'feeds': 1,\n",
       " 'might': 1,\n",
       " 'still': 1,\n",
       " 'incomplete': 1,\n",
       " 'needs': 1,\n",
       " 'so': 1,\n",
       " 'future': 1,\n",
       " 'occurrences': 1}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'21st',\n",
       " 'a',\n",
       " 'about',\n",
       " 'absolute',\n",
       " 'accurate',\n",
       " 'advantage',\n",
       " 'all',\n",
       " 'also',\n",
       " 'amount',\n",
       " 'analysis',\n",
       " 'analytics',\n",
       " 'and',\n",
       " 'are',\n",
       " 'array',\n",
       " 'as',\n",
       " 'at',\n",
       " 'away',\n",
       " 'backend',\n",
       " 'based',\n",
       " 'basics',\n",
       " 'be',\n",
       " 'because',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'book',\n",
       " 'but',\n",
       " 'by',\n",
       " 'california',\n",
       " 'called',\n",
       " 'can',\n",
       " 'center',\n",
       " 'century',\n",
       " 'clean',\n",
       " 'cleaned',\n",
       " 'cleaning',\n",
       " 'comes',\n",
       " 'common',\n",
       " 'component',\n",
       " 'concepts',\n",
       " 'conducted',\n",
       " 'confident',\n",
       " 'coolest',\n",
       " 'core',\n",
       " 'curated',\n",
       " 'data',\n",
       " 'database',\n",
       " 'datascientists',\n",
       " 'datasets',\n",
       " 'diego',\n",
       " 'direction',\n",
       " 'diverse',\n",
       " 'domainthe',\n",
       " 'done',\n",
       " 'downstream',\n",
       " 'dry',\n",
       " 'during',\n",
       " 'efficientlydata',\n",
       " 'emphasis',\n",
       " 'emphasize',\n",
       " 'end',\n",
       " 'enough',\n",
       " 'ensures',\n",
       " 'equips',\n",
       " 'especially',\n",
       " 'essential',\n",
       " 'example',\n",
       " 'excel',\n",
       " 'extract',\n",
       " 'extreme',\n",
       " 'feeds',\n",
       " 'financial',\n",
       " 'fire',\n",
       " 'focusing',\n",
       " 'for',\n",
       " 'forest',\n",
       " 'format',\n",
       " 'formatted',\n",
       " 'from',\n",
       " 'fundamental',\n",
       " 'future',\n",
       " 'gather',\n",
       " 'handle',\n",
       " 'heat',\n",
       " 'highquality',\n",
       " 'how',\n",
       " 'ideas',\n",
       " 'imagery',\n",
       " 'in',\n",
       " 'incomplete',\n",
       " 'incorrect',\n",
       " 'internet',\n",
       " 'into',\n",
       " 'invaluable',\n",
       " 'is',\n",
       " 'it',\n",
       " 'job',\n",
       " 'jumps',\n",
       " 'knowledge',\n",
       " 'languages',\n",
       " 'large',\n",
       " 'learn',\n",
       " 'libraries',\n",
       " 'mainly',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'meaningful',\n",
       " 'might',\n",
       " 'missing',\n",
       " 'most',\n",
       " 'must',\n",
       " 'myriad',\n",
       " 'nature',\n",
       " 'need',\n",
       " 'needs',\n",
       " 'numpy',\n",
       " 'occurrences',\n",
       " 'of',\n",
       " 'on',\n",
       " 'one',\n",
       " 'or',\n",
       " 'other',\n",
       " 'over',\n",
       " 'pandas',\n",
       " 'pipeline',\n",
       " 'popular',\n",
       " 'practice',\n",
       " 'practitioner',\n",
       " 'prebuilt',\n",
       " 'predict',\n",
       " 'preprocessed',\n",
       " 'problem',\n",
       " 'process',\n",
       " 'processesand',\n",
       " 'prominent',\n",
       " 'properly',\n",
       " 'python',\n",
       " 'quickly',\n",
       " 'ready',\n",
       " 'realworldexamples',\n",
       " 'refined',\n",
       " 'reformat',\n",
       " 'requirements',\n",
       " 'routinely',\n",
       " 'routines',\n",
       " 'same',\n",
       " 'san',\n",
       " 'satellite',\n",
       " 'science',\n",
       " 'scientist',\n",
       " 'sensors',\n",
       " 'short',\n",
       " 'should',\n",
       " 'so',\n",
       " 'sourced',\n",
       " 'sources',\n",
       " 'specialized',\n",
       " 'spread',\n",
       " 'starts',\n",
       " 'stations',\n",
       " 'stay',\n",
       " 'still',\n",
       " 'structures',\n",
       " 'such',\n",
       " 'summers',\n",
       " 'supercomputer',\n",
       " 'sure',\n",
       " 'tables',\n",
       " 'take',\n",
       " 'taking',\n",
       " 'teaches',\n",
       " 'techniques',\n",
       " 'that',\n",
       " 'the',\n",
       " 'then',\n",
       " 'thereafter',\n",
       " 'these',\n",
       " 'this',\n",
       " 'through',\n",
       " 'to',\n",
       " 'tool',\n",
       " 'tools',\n",
       " 'traditional',\n",
       " 'transform',\n",
       " 'trnsform',\n",
       " 'truly',\n",
       " 'twitter',\n",
       " 'ucsd',\n",
       " 'university',\n",
       " 'used',\n",
       " 'useful',\n",
       " 'using',\n",
       " 'valuable',\n",
       " 'vaults',\n",
       " 'very',\n",
       " 'way',\n",
       " 'we',\n",
       " 'weather',\n",
       " 'whole',\n",
       " 'why',\n",
       " 'wildfires',\n",
       " 'will',\n",
       " 'with',\n",
       " 'world',\n",
       " 'wrangling',\n",
       " 'you',\n",
       " 'your'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set function returns the unique words in the text\n",
    "unique_words = set(list_of_words)\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words_list = list(unique_words)\n",
    "len(unique_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This will create a histograms of words with the number of times they were repeated in the list of unque words. \n",
    "# It should be 1 for all words\n",
    "hist = {}\n",
    "for x in unique_words_list:\n",
    "    hist[x] = hist.get(x, 0) + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}